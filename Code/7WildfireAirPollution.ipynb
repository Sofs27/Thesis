{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI Goals:\n",
    "\n",
    "i) investigar as ligações entre a atividade do fogo, conforme medido pelo FRP (Fire Radiative Power), e as concentrações de poluentes e avaliar a zona espacial e temporal de influência da atividade dos incêndios florestais.\n",
    "\n",
    "(ii) investigar a utilização de FRP como ferramenta para filtrar a contribuição do fumo de biomassa para os registos de poluição atmosférica em bacias atmosféricas urbanas, nomeadamente as emissões de carbono resultantes de incêndios florestais graves.\n",
    "\n",
    "(iii) desenvolver abordagens multirriscos para caracterizar o comportamento conjunto de múltiplos perigos e riscos consequentes e avaliar o papel desempenhado por condições anteriores e simultâneas de seca e/ou calor na exacerbação de incêndios rurais e consequentes ondas de fumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine datasets (labeled dataset that contains info about labels and FRP & pollutants statistics) by day and pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outdated\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "pm25_path = r\"D:\\IPMA\\CAMS\\chem_multlvl\\daily_pm2p5_stats.nc\"\n",
    "fire_path = r\"D:\\IPMA\\FRP\\fire_labels_by_region\\fire_data_Greece.nc\"\n",
    "output_path = r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\"\n",
    "\n",
    "ds_pm25 = xr.open_dataset(pm25_path)\n",
    "ds_fire = xr.open_dataset(fire_path)\n",
    "\n",
    "# Extract Year, Month, Day arrays\n",
    "years = ds_pm25['Year'].values\n",
    "months = ds_pm25['Month'].values\n",
    "days = ds_pm25['Day'].values\n",
    "\n",
    "# Create all combinations of year, month, day\n",
    "ymd = pd.MultiIndex.from_product([years, months, days], names=['year', 'month', 'day']).to_frame(index=False)\n",
    "\n",
    "# Remove invalid dates by trying to convert and catching errors\n",
    "def is_valid_date(row):\n",
    "    try:\n",
    "        pd.Timestamp(year=int(row['year']), month=int(row['month']), day=int(row['day']))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "valid_mask = ymd.apply(is_valid_date, axis=1)\n",
    "ymd_valid = ymd[valid_mask].reset_index(drop=True)\n",
    "\n",
    "# Convert valid dates to datetime\n",
    "time_index = pd.to_datetime(ymd_valid)\n",
    "\n",
    "# Now, flatten pm25 data and select only valid time indices\n",
    "ds_pm25_stack = ds_pm25.stack(time=('Year', 'Month', 'Day'))\n",
    "\n",
    "# Select only valid times in pm25_stack corresponding to valid dates\n",
    "# valid_mask is boolean over all combinations; stack time dims correspond 1:1 to ymd rows\n",
    "ds_pm25_stack = ds_pm25_stack.isel(time=valid_mask.values)\n",
    "\n",
    "# Assign new time coordinate with valid dates\n",
    "ds_pm25_stack = ds_pm25_stack.assign_coords(time=time_index)\n",
    "\n",
    "# Select overlapping time range with fire dataset\n",
    "start_time = max(ds_pm25_stack.time.values[0], ds_fire.time.values[0])\n",
    "end_time = min(ds_pm25_stack.time.values[-1], ds_fire.time.values[-1])\n",
    "\n",
    "ds_pm25_sel = ds_pm25_stack.sel(time=slice(start_time, end_time))\n",
    "ds_fire_sel = ds_fire.sel(time=slice(start_time, end_time))\n",
    "\n",
    "# Check lat/lon match\n",
    "assert np.allclose(ds_pm25_sel.latitude.values, ds_fire_sel.latitude.values), \"Latitude mismatch\"\n",
    "assert np.allclose(ds_pm25_sel.longitude.values, ds_fire_sel.longitude.values), \"Longitude mismatch\"\n",
    "\n",
    "# Merge datasets\n",
    "ds_merged = xr.merge([ds_pm25_sel, ds_fire_sel])\n",
    "\n",
    "# Save merged dataset\n",
    "ds_merged.to_netcdf(output_path)\n",
    "\n",
    "print(f\"Merged dataset saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==== File paths ====\n",
    "pm25_path = r\"D:\\IPMA\\CAMS\\chem_singlvl\\daily_pm2p5_stats.nc\"\n",
    "fire_path = r\"D:\\IPMA\\FRP\\fire_labels_by_region\\fire_data_Spain.nc\"\n",
    "mask_path = r\"D:\\IPMA\\Countries\\Spain_mask.nc\" \n",
    "output_path = r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\"\n",
    "\n",
    "# ==== Load datasets ====\n",
    "ds_pm25 = xr.open_dataset(pm25_path)\n",
    "ds_fire = xr.open_dataset(fire_path)\n",
    "mask_ds = xr.open_dataset(mask_path)\n",
    "\n",
    "# ==== Load mask variable ====\n",
    "# Assuming mask variable is 1 inside the country and 0 outside\n",
    "mask = mask_ds[\"mask\"]  # change \"mask\" if your variable name is different\n",
    "\n",
    "# ==== Extract Year, Month, Day ====\n",
    "years = ds_pm25['Year'].values\n",
    "months = ds_pm25['Month'].values\n",
    "days = ds_pm25['Day'].values\n",
    "\n",
    "# ==== Create all combinations ====\n",
    "ymd = pd.MultiIndex.from_product(\n",
    "    [years, months, days],\n",
    "    names=['year', 'month', 'day']\n",
    ").to_frame(index=False)\n",
    "\n",
    "# ==== Remove invalid dates ====\n",
    "def is_valid_date(row):\n",
    "    try:\n",
    "        pd.Timestamp(year=int(row['year']), month=int(row['month']), day=int(row['day']))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "valid_mask = ymd.apply(is_valid_date, axis=1)\n",
    "ymd_valid = ymd[valid_mask].reset_index(drop=True)\n",
    "\n",
    "# ==== Convert valid dates to datetime ====\n",
    "time_index = pd.to_datetime(ymd_valid)\n",
    "\n",
    "# ==== Flatten pollutant data ====\n",
    "ds_pm25_stack = ds_pm25.stack(time=('Year', 'Month', 'Day'))\n",
    "\n",
    "# Keep only valid dates\n",
    "ds_pm25_stack = ds_pm25_stack.isel(time=valid_mask.values)\n",
    "\n",
    "# Assign new datetime coordinate\n",
    "ds_pm25_stack = ds_pm25_stack.assign_coords(time=time_index)\n",
    "\n",
    "# ==== Select overlapping time ====\n",
    "start_time = max(ds_pm25_stack.time.values[0], ds_fire.time.values[0])\n",
    "end_time = min(ds_pm25_stack.time.values[-1], ds_fire.time.values[-1])\n",
    "\n",
    "ds_pm25_sel = ds_pm25_stack.sel(time=slice(start_time, end_time))\n",
    "ds_fire_sel = ds_fire.sel(time=slice(start_time, end_time))\n",
    "\n",
    "# ==== Check lat/lon match ====\n",
    "assert np.allclose(ds_pm25_sel.latitude.values, ds_fire_sel.latitude.values), \"Latitude mismatch\"\n",
    "assert np.allclose(ds_pm25_sel.longitude.values, ds_fire_sel.longitude.values), \"Longitude mismatch\"\n",
    "assert np.allclose(ds_pm25_sel.latitude.values, mask.latitude.values), \"Latitude mismatch with mask\"\n",
    "assert np.allclose(ds_pm25_sel.longitude.values, mask.longitude.values), \"Longitude mismatch with mask\"\n",
    "\n",
    "# ==== Apply mask to both datasets ====\n",
    "ds_pm25_masked = ds_pm25_sel.where(mask == 1)\n",
    "ds_fire_masked = ds_fire_sel.where(mask == 1)\n",
    "\n",
    "# ==== Merge datasets ====\n",
    "ds_merged = xr.merge([ds_pm25_masked, ds_fire_masked])\n",
    "\n",
    "# ==== Save ====\n",
    "ds_merged.to_netcdf(output_path)\n",
    "print(f\"Merged dataset saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
