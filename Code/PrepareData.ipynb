{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main pollutants PM10 & PM2.5, NO2, CO2, O3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAMS global reanalysis EAC4 - Data Preparation (according to what Virgilio gave in matlab scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To separate monthly files when downloading the full year - DONE for 2023-2024\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"D:\\CAMS\\CAMS_global_reanalysis_EAC4\\chem_singlvl\\CAMS_global_reanalysis_EAC4_chem_singlvl_2024.nc\" #change path accordingly\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# Ensure valid_time is a datetime object\n",
    "ds['valid_time'] = pd.to_datetime(ds['valid_time'].values)\n",
    "\n",
    "# Get unique years in the dataset\n",
    "years = pd.Series(ds['valid_time'].dt.year.values).unique()\n",
    "\n",
    "# Iterate through years and months\n",
    "dest_folder = r\"D:\\CAMS\\CAMS_global_reanalysis_EAC4\\chem_singlvl\"\n",
    "for year in years:\n",
    "    for month in range(1, 13):\n",
    "        # Filter dataset for the given year and month\n",
    "        monthly_ds = ds.sel(valid_time=(ds.valid_time.dt.year == year) & (ds.valid_time.dt.month == month))\n",
    "\n",
    "        if monthly_ds.valid_time.size > 0:  # Only save if data exists for the month\n",
    "            output_filename = rf\"{dest_folder}\\CAMS_global_reanalysis_EAC4_chem_singlvl_{year}{month:02d}.nc\"\n",
    "            monthly_ds.to_netcdf(output_filename)\n",
    "            print(f\"Saved {output_filename}\")\n",
    "\n",
    "# Close the dataset\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change valid_time to time (so it matches) - DONE for 2023-2024\n",
    "\n",
    "import xarray as xr\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to your directory containing the NetCDF files\n",
    "input_dir = r\"D:\\CAMS\\CAMS_global_reanalysis_EAC4\\chem_singlvl\"\n",
    "output_dir = r\"D:\\CAMS\\CAMS_global_reanalysis_EAC4\\chem_singlvl\\final_2003_2024\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get all NetCDF files in the input directory\n",
    "nc_files = glob.glob(os.path.join(input_dir, \"*.nc\"))\n",
    "\n",
    "# Loop through each file\n",
    "for file_path in nc_files:\n",
    "    print(f\"Processing {file_path}...\")\n",
    "\n",
    "    # Open the NetCDF file\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    # Check if 'valid_time' exists and rename it to 'time'\n",
    "    if 'valid_time' in ds:\n",
    "        ds = ds.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # Get the filename and create the output path in the new directory\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path))\n",
    "\n",
    "    # Save the updated dataset to the output directory (overwrite original file in the new folder)\n",
    "    ds.to_netcdf(output_file)\n",
    "\n",
    "    print(f\"Renamed 'valid_time' to 'time' and saved to {output_file}\")\n",
    "\n",
    "print(\"Renaming and saving to new folder complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert coords from 0 to 360 to -180 to 180 - DONE for 2003-2022\n",
    "\n",
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = r\"D:\\CAMS\\CAMS_global_reanalysis_EAC4\\chem_singlvl\\raw_2003_2022\"\n",
    "output_folder = r\"D:\\CAMS\\CAMS_global_reanalysis_EAC4\\chem_singlvl\\transformation_2003_2022\"\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get list of NetCDF files in the input folder\n",
    "nc_files = [f for f in os.listdir(input_folder) if f.endswith(\".nc\")]\n",
    "\n",
    "# Process each file\n",
    "for nc_file in nc_files:\n",
    "    input_path = os.path.join(input_folder, nc_file)\n",
    "    output_path = os.path.join(output_folder, nc_file)\n",
    "\n",
    "    print(f\"Processing: {nc_file}\")\n",
    "\n",
    "    # Open the dataset\n",
    "    ds = xr.open_dataset(input_path)\n",
    "\n",
    "    # Extract longitude and latitude\n",
    "    lon = ds['longitude'].values  # (480,)\n",
    "    lat = ds['latitude'].values   # (241,)\n",
    "\n",
    "    # Convert longitude from 0-360 to -180 to 180\n",
    "    lon2 = (lon + 180) % 360 - 180\n",
    "\n",
    "    # Swap the first and second halves\n",
    "    lon3 = np.copy(lon2)\n",
    "    lon3[:240] = lon2[240:480]\n",
    "    lon3[240:480] = lon2[:240]\n",
    "\n",
    "    # Create a meshgrid (not strictly needed for saving, but useful)\n",
    "    LON, LAT = np.meshgrid(lon3, lat)\n",
    "\n",
    "    # Apply the same transformation to pm10, pm1, and pm2p5\n",
    "    for var in [\"pm10\", \"pm1\", \"pm2p5\"]:\n",
    "        if var in ds:\n",
    "            data = ds[var].values  # Shape: (time, lat, lon)\n",
    "            transformed_data = np.copy(data)\n",
    "\n",
    "            # Swap the longitude axis (last axis)\n",
    "            transformed_data[:, :, :240] = data[:, :, 240:480]\n",
    "            transformed_data[:, :, 240:480] = data[:, :, :240]\n",
    "\n",
    "            # Replace the dataset variable with the corrected data\n",
    "            ds[var].values = transformed_data\n",
    "\n",
    "    # Update longitude in the dataset\n",
    "    ds = ds.assign_coords(longitude=lon3)\n",
    "\n",
    "    # Save the modified dataset\n",
    "    ds.to_netcdf(output_path)\n",
    "\n",
    "    print(f\"Saved transformed file: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To crop to study area - DONE for 2003-2022\n",
    "\n",
    "import xarray as xr\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define your study area (lat_max, lon_min, lat_min, lon_max)\n",
    "lat_max, lon_min, lat_min, lon_max = 66, -12, 34, 36\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = r\"D:\\CAMS\\CAMS_global_reanalysis_EAC4\\chem_singlvl\\transformation_2003_2022\"\n",
    "output_dir = r\"D:\\CAMS\\CAMS_global_reanalysis_EAC4\\chem_singlvl\\cropped_2003_2022\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get all NetCDF files in the input directory\n",
    "nc_files = glob.glob(os.path.join(input_dir, \"*.nc\"))\n",
    "\n",
    "for file_path in nc_files:\n",
    "    print(f\"Processing {file_path}...\")\n",
    "\n",
    "    # Open the NetCDF file\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    # Ensure latitude slicing is correct (since it decreases from 90 to -90)\n",
    "    ds_cropped = ds.sel(\n",
    "        latitude=slice(lat_max, lat_min),  # lat_max is greater than lat_min\n",
    "        longitude=slice(lon_min, lon_max)  # lon_min is less than lon_max\n",
    "    )\n",
    "\n",
    "    # Define output file path\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path))\n",
    "\n",
    "    # Save the cropped dataset\n",
    "    ds_cropped.to_netcdf(output_file)\n",
    "    print(f\"Saved cropped file to {output_file}\")\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
