{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5837e9",
   "metadata": {},
   "source": [
    "mean +- standard error of mean of pollutants on day without fire, with fire and up to 5 days after fire outbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52216297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pollutant concentrations by fire label (spatial average across Portugal):\n",
      "                Label  PM10 Mean (µg/m³)  PM10 SEM (µg/m³)  PM2.5 Mean (µg/m³)  PM2.5 SEM (µg/m³)  NO2 Mean (µg/m³)  NO2 SEM (µg/m³)  CO Mean (µg/m³)  CO SEM (µg/m³)  NO Mean (µg/m³)  NO SEM (µg/m³)\n",
      "              No fire          15.096757          0.240055           10.208306           0.173664          5.472955         0.036699       167.779115        1.175729         0.590265        0.022267\n",
      "Day 0 (Fire outbreak)          45.886020          9.656258           32.863526           7.041121          7.475000         0.747153       299.751848       51.305623         2.228505        0.824601\n",
      "                Day 1          97.716508         29.250056           70.534644          21.259187         10.964914         2.256131       506.716504      134.266926         4.769814        2.165469\n",
      "                Day 2         182.308947         45.015734          132.549703          33.439520         17.231838         4.008635      1036.756722      353.414406        15.458376        7.219977\n",
      "                Day 3         213.443230         55.439916          154.924153          40.759322         21.286752         5.405691      1321.475395      462.783253        19.509572        9.371480\n",
      "                Day 4         212.031912         56.431166          153.576841          41.123176         19.979507         4.640795      1203.708739      360.728675        16.438971        5.770418\n",
      "                Day 5         191.692520         54.593626          137.794367          39.290401         17.412301         3.422059       922.677013      248.161870         8.958207        2.967680\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Portugal'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000    \n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Portugal):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec16065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pollutant concentrations by fire label (spatial average across Italy):\n",
      "                Label  PM10 Mean (µg/m³)  PM10 SEM (µg/m³)  PM2.5 Mean (µg/m³)  PM2.5 SEM (µg/m³)  NO2 Mean (µg/m³)  NO2 SEM (µg/m³)  CO Mean (µg/m³)  CO SEM (µg/m³)  NO Mean (µg/m³)  NO SEM (µg/m³)\n",
      "              No fire          21.032259          0.151412           14.823289           0.109723          9.571507         0.055528       225.298092        0.911101         2.182623        0.038641\n",
      "Day 0 (Fire outbreak)          28.344443          3.841608           20.155887           2.786949          9.392919         1.056645       233.280944       19.220328         1.646102        0.565466\n",
      "                Day 1          45.923278          7.305911           32.983355           5.278086         11.120176         1.314471       298.765534       28.002509         1.362950        0.346480\n",
      "                Day 2          48.739358         12.259807           34.876954           8.912328         10.923386         2.033146       307.158930       56.920166         1.366858        0.586027\n",
      "                Day 3          48.442269          3.684341           34.681774           2.728996         10.285214         0.919067       334.167452       27.794155         0.709102        0.105706\n",
      "                Day 4          41.269221          4.593632           29.507354           3.335968          9.757264         0.890112       293.416610       25.604648         0.437245        0.082963\n",
      "                Day 5          67.568797          2.604636           48.805979           1.910178         11.837718         0.244753       436.229761       11.562939         2.160815        0.062139\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Italy'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Italy):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5400942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pollutant concentrations by fire label (spatial average across Spain):\n",
      "                Label  PM10 Mean (µg/m³)  PM10 SEM (µg/m³)  PM2.5 Mean (µg/m³)  PM2.5 SEM (µg/m³)  NO2 Mean (µg/m³)  NO2 SEM (µg/m³)  CO Mean (µg/m³)  CO SEM (µg/m³)  NO Mean (µg/m³)  NO SEM (µg/m³)\n",
      "              No fire          15.303822          0.138710           10.660586           0.101369          6.713976         0.042117       179.675069        0.706041         1.065766        0.024024\n",
      "Day 0 (Fire outbreak)          30.919225          7.826939           22.153211           5.730354          7.640597         0.949351       244.667172       40.292259         2.064513        0.923958\n",
      "                Day 1          64.766813         15.502962           46.728961          11.290378          9.582287         1.350382       420.424068       82.593527         5.297486        1.760777\n",
      "                Day 2          80.894601         16.983552           58.491989          12.370796         11.797910         1.810596       494.854970       90.496916         5.369704        1.683429\n",
      "                Day 3         118.676581         32.946047           85.928668          24.066932         14.891454         2.775383       766.256084      219.421283        11.154176        4.550445\n",
      "                Day 4         127.541362         41.710668           92.318419          30.314037         15.816056         3.379472       683.321048      222.521145         9.049442        4.136038\n",
      "                Day 5         280.384825        144.123704          201.709778         103.723518         26.682651         8.729706      1149.237740      525.590800        15.185939        8.565895\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Spain'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Spain):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff276096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pollutant concentrations by fire label (spatial average across Greece):\n",
      "                Label  PM10 Mean (µg/m³)  PM10 SEM (µg/m³)  PM2.5 Mean (µg/m³)  PM2.5 SEM (µg/m³)  NO2 Mean (µg/m³)  NO2 SEM (µg/m³)  CO Mean (µg/m³)  CO SEM (µg/m³)  NO Mean (µg/m³)  NO SEM (µg/m³)\n",
      "              No fire          17.370958          0.178065           12.347840           0.129621          4.253410         0.030815       181.039304        0.637393         0.507762        0.011021\n",
      "Day 0 (Fire outbreak)          41.560897         13.200809           29.979675           9.569354          5.979247         1.176284       264.980246       46.437584         1.140654        0.481704\n",
      "                Day 1         115.732091         43.005361           83.915637          31.429443         12.473766         4.026267       613.641962      228.567842         4.726936        3.225457\n",
      "                Day 2         141.804015         53.015578          104.165278          39.594776         17.518174         6.849168       977.714549      451.650038        12.383760        9.437996\n",
      "                Day 3         245.660557         33.127283          180.626877          24.657543         28.259810         4.869299      2005.264147      273.345398        33.545611        4.529399\n",
      "                Day 4         115.538606         18.353848           84.481962          13.631738         13.368619         3.015095       834.248208      203.453227         4.461093        1.939951\n",
      "                Day 5          87.621490          4.228566           63.657337           3.127232          9.695104         0.241431       477.319816       25.491130         1.088483        0.080977\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Greece'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Greece):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e2468",
   "metadata": {},
   "source": [
    "Divide daily concentrations of pollutants into quartiles Q1 (lowest), Q2, Q3 and Q4 (highest) for days when fires occurred and days they did not - Assess the impact of fire events on the concentration of air pollutants. Calculation of percentage of days (non-wildfire and wildfire) in each of the four qaurtiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab12b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1954796649.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1954796649.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1954796649.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1954796649.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts table:\n",
      "quartile  fire   Q1   Q2   Q3   Q4 pollutant\n",
      "0          0.0  385  384  384  384        CO\n",
      "1          1.0   36   36   36   36        CO\n",
      "2          0.0  385  384  384  384     PM2.5\n",
      "3          1.0   36   36   36   36     PM2.5\n",
      "4          0.0  385  384  384  384      PM10\n",
      "5          1.0   36   36   36   36      PM10\n",
      "6          0.0  385  384  384  384       NO2\n",
      "7          1.0   36   36   36   36       NO2\n",
      "8          0.0  385  384  384  384        NO\n",
      "9          1.0   36   36   36   36        NO\n",
      "\n",
      "Percentages table:\n",
      "quartile  fire         Q1         Q2         Q3         Q4 pollutant\n",
      "0          0.0  25.048796  24.983735  24.983735  24.983735        CO\n",
      "1          1.0  25.000000  25.000000  25.000000  25.000000        CO\n",
      "2          0.0  25.048796  24.983735  24.983735  24.983735     PM2.5\n",
      "3          1.0  25.000000  25.000000  25.000000  25.000000     PM2.5\n",
      "4          0.0  25.048796  24.983735  24.983735  24.983735      PM10\n",
      "5          1.0  25.000000  25.000000  25.000000  25.000000      PM10\n",
      "6          0.0  25.048796  24.983735  24.983735  24.983735       NO2\n",
      "7          1.0  25.000000  25.000000  25.000000  25.000000       NO2\n",
      "8          0.0  25.048796  24.983735  24.983735  24.983735        NO\n",
      "9          1.0  25.000000  25.000000  25.000000  25.000000        NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1954796649.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# --- List of pollutant files (example with CO and PM2.5) ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if different variable name\n",
    "    fire_flag = ds[\"fire_binary_Portugal\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # Summary: counts\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Summary: percentages\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0f95ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\3897458115.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\3897458115.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\3897458115.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\3897458115.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts table:\n",
      "quartile  fire     Q1     Q2     Q3     Q4 pollutant\n",
      "0          0.0  10282  10282  10281  10282        CO\n",
      "1          1.0      6      6      6      6        CO\n",
      "2          0.0  10282  10282  10281  10282     PM2.5\n",
      "3          1.0      6      6      6      6     PM2.5\n",
      "4          0.0  10282  10281  10281  10282      PM10\n",
      "5          1.0      6      6      6      6      PM10\n",
      "6          0.0  10282  10282  10281  10282       NO2\n",
      "7          1.0      6      6      6      6       NO2\n",
      "8          0.0  10277  10277  10277  10277        NO\n",
      "9          1.0      6      6      6      6        NO\n",
      "\n",
      "Percentages table:\n",
      "quartile  fire         Q1         Q2         Q3         Q4 pollutant\n",
      "0          0.0  25.000608  25.000608  24.998176  25.000608        CO\n",
      "1          1.0  25.000000  25.000000  25.000000  25.000000        CO\n",
      "2          0.0  25.000608  25.000608  24.998176  25.000608     PM2.5\n",
      "3          1.0  25.000000  25.000000  25.000000  25.000000     PM2.5\n",
      "4          0.0  25.001216  24.998784  24.998784  25.001216      PM10\n",
      "5          1.0  25.000000  25.000000  25.000000  25.000000      PM10\n",
      "6          0.0  25.000608  25.000608  24.998176  25.000608       NO2\n",
      "7          1.0  25.000000  25.000000  25.000000  25.000000       NO2\n",
      "8          0.0  25.000000  25.000000  25.000000  25.000000        NO\n",
      "9          1.0  25.000000  25.000000  25.000000  25.000000        NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\3897458115.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# --- List of pollutant files (example with CO and PM2.5) ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if different variable name\n",
    "    fire_flag = ds[\"fire_binary_Italy\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # Summary: counts\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Summary: percentages\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24d5c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1368008672.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1368008672.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1368008672.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1368008672.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts table:\n",
      "quartile  fire     Q1     Q2     Q3     Q4 pollutant\n",
      "0          0.0  11124  11123  11123  11123        CO\n",
      "1          1.0     88     87     87     87        CO\n",
      "2          0.0  11124  11123  11123  11123     PM2.5\n",
      "3          1.0     88     87     87     87     PM2.5\n",
      "4          0.0  11124  11123  11123  11123      PM10\n",
      "5          1.0     88     87     87     87      PM10\n",
      "6          0.0  11124  11123  11123  11123       NO2\n",
      "7          1.0     88     87     87     87       NO2\n",
      "8          0.0  11123  11122  11122  11123        NO\n",
      "9          1.0     88     87     87     87        NO\n",
      "\n",
      "Percentages table:\n",
      "quartile  fire         Q1         Q2         Q3         Q4 pollutant\n",
      "0          0.0  25.001686  24.999438  24.999438  24.999438        CO\n",
      "1          1.0  25.214900  24.928367  24.928367  24.928367        CO\n",
      "2          0.0  25.001686  24.999438  24.999438  24.999438     PM2.5\n",
      "3          1.0  25.214900  24.928367  24.928367  24.928367     PM2.5\n",
      "4          0.0  25.001686  24.999438  24.999438  24.999438      PM10\n",
      "5          1.0  25.214900  24.928367  24.928367  24.928367      PM10\n",
      "6          0.0  25.001686  24.999438  24.999438  24.999438       NO2\n",
      "7          1.0  25.214900  24.928367  24.928367  24.928367       NO2\n",
      "8          0.0  25.001124  24.998876  24.998876  25.001124        NO\n",
      "9          1.0  25.214900  24.928367  24.928367  24.928367        NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\1368008672.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# --- List of pollutant files (example with CO and PM2.5) ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if different variable name\n",
    "    fire_flag = ds[\"fire_binary_Spain\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # Summary: counts\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Summary: percentages\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed3a165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\4030963801.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\4030963801.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\4030963801.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\4030963801.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts table:\n",
      "quartile  fire    Q1    Q2    Q3    Q4 pollutant\n",
      "0          0.0  4955  4954  4954  4954        CO\n",
      "1          1.0    15    14    14    15        CO\n",
      "2          0.0  4955  4954  4954  4954     PM2.5\n",
      "3          1.0    15    14    14    15     PM2.5\n",
      "4          0.0  4953  4952  4952  4952      PM10\n",
      "5          1.0    15    14    14    15      PM10\n",
      "6          0.0  4955  4954  4954  4954       NO2\n",
      "7          1.0    15    14    14    15       NO2\n",
      "8          0.0  4953  4953  4953  4953        NO\n",
      "9          1.0    15    14    14    15        NO\n",
      "\n",
      "Percentages table:\n",
      "quartile  fire         Q1         Q2         Q3         Q4 pollutant\n",
      "0          0.0  25.003785  24.998738  24.998738  24.998738        CO\n",
      "1          1.0  25.862069  24.137931  24.137931  25.862069        CO\n",
      "2          0.0  25.003785  24.998738  24.998738  24.998738     PM2.5\n",
      "3          1.0  25.862069  24.137931  24.137931  25.862069     PM2.5\n",
      "4          0.0  25.003786  24.998738  24.998738  24.998738      PM10\n",
      "5          1.0  25.862069  24.137931  24.137931  25.862069      PM10\n",
      "6          0.0  25.003785  24.998738  24.998738  24.998738       NO2\n",
      "7          1.0  25.862069  24.137931  24.137931  25.862069       NO2\n",
      "8          0.0  25.000000  25.000000  25.000000  25.000000        NO\n",
      "9          1.0  25.862069  24.137931  24.137931  25.862069        NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_8160\\4030963801.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# --- List of pollutant files (example with CO and PM2.5) ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if different variable name\n",
    "    fire_flag = ds[\"fire_binary_Greece\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # Summary: counts\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Summary: percentages\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f1ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cf28794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CO...\n",
      "Processing PM2.5...\n",
      "Processing PM10...\n",
      "Processing NO2...\n",
      "Processing NO...\n",
      "\n",
      "Counts of days in each quartile by pollutant & fire status:\n",
      "quartile         Q1   Q2   Q3      Q4\n",
      "Pollutant Fire                       \n",
      "CO        0.0   408  369  360  187967\n",
      "          1.0    45   39   39    3637\n",
      "PM2.5     0.0   408  363  411  187922\n",
      "          1.0    32   33   38    3657\n",
      "PM10      0.0   404  387  362  187951\n",
      "          1.0    30   38   35    3657\n",
      "NO2       0.0   401  381  381  187941\n",
      "          1.0    53   36   32    3639\n",
      "NO        0.0   389  383  389  187943\n",
      "          1.0    32   37   42    3649\n",
      "\n",
      "Percentages of days in each quartile by pollutant & fire status:\n",
      "quartile              Q1        Q2        Q3         Q4\n",
      "Pollutant Fire                                         \n",
      "CO        0.0   0.215754  0.195131  0.190371  99.398744\n",
      "          1.0   1.196809  1.037234  1.037234  96.728723\n",
      "PM2.5     0.0   0.215754  0.191958  0.217341  99.374947\n",
      "          1.0   0.851064  0.877660  1.010638  97.260638\n",
      "PM10      0.0   0.213639  0.204649  0.191429  99.390283\n",
      "          1.0   0.797872  1.010638  0.930851  97.260638\n",
      "NO2       0.0   0.212053  0.201476  0.201476  99.384995\n",
      "          1.0   1.409574  0.957447  0.851064  96.781915\n",
      "NO        0.0   0.205707  0.202534  0.205707  99.386052\n",
      "          1.0   0.851064  0.984043  1.117021  97.047872\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Your pollutant NetCDF files\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "results_counts = {}\n",
    "results_pct = {}\n",
    "\n",
    "for pollutant, filepath in files.items():\n",
    "    print(f\"Processing {pollutant}...\")\n",
    "\n",
    "    # Open dataset\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    # Change \"Mean\" if variable name differs\n",
    "    df = ds[\"Mean\"].to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = ds[\"fire_binary_Portugal\"].to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Global quartiles (all days together)\n",
    "    quantiles = df[\"pollutant\"].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "\n",
    "    # Assign quartile\n",
    "    def assign_quartile(x):\n",
    "        if x <= quantiles[0.25]:\n",
    "            return \"Q1\"\n",
    "        elif x <= quantiles[0.5]:\n",
    "            return \"Q2\"\n",
    "        elif x <= quantiles[0.75]:\n",
    "            return \"Q3\"\n",
    "        else:\n",
    "            return \"Q4\"\n",
    "\n",
    "    df[\"quartile\"] = df[\"pollutant\"].apply(assign_quartile)\n",
    "\n",
    "    # Counts & percentages\n",
    "    summary_counts = df.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    results_counts[pollutant] = summary_counts\n",
    "    results_pct[pollutant] = summary_pct\n",
    "\n",
    "# Combine into big tables\n",
    "counts_table = pd.concat(results_counts, names=[\"Pollutant\", \"Fire\"])\n",
    "pct_table = pd.concat(results_pct, names=[\"Pollutant\", \"Fire\"])\n",
    "\n",
    "print(\"\\nCounts of days in each quartile by pollutant & fire status:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages of days in each quartile by pollutant & fire status:\")\n",
    "print(pct_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d797334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CO...\n",
      "Processing PM2.5...\n",
      "Processing PM10...\n",
      "Processing NO2...\n",
      "Processing NO...\n",
      "\n",
      "Counts of days in each quartile by pollutant & fire status:\n",
      "quartile           Q1     Q2     Q3      Q4\n",
      "Pollutant Fire                             \n",
      "CO        0.0   10237  10315  10354  928270\n",
      "          1.0       9      3      6    5126\n",
      "PM2.5     0.0   10498  10124  10325  928229\n",
      "          1.0       7      5      5    5127\n",
      "PM10      0.0   10493  10161  10244  928278\n",
      "          1.0       7      4      6    5127\n",
      "NO2       0.0   10239  10376  10399  928162\n",
      "          1.0      10      3      4    5127\n",
      "NO        0.0   10293  10163  10412  928308\n",
      "          1.0       6      5      7    5126\n",
      "\n",
      "Percentages of days in each quartile by pollutant & fire status:\n",
      "quartile              Q1        Q2        Q3         Q4\n",
      "Pollutant Fire                                         \n",
      "CO        0.0   1.067270  1.075402  1.079468  96.777859\n",
      "          1.0   0.174961  0.058320  0.116641  99.650078\n",
      "PM2.5     0.0   1.094481  1.055489  1.076445  96.773585\n",
      "          1.0   0.136081  0.097201  0.097201  99.669518\n",
      "PM10      0.0   1.093960  1.059347  1.068000  96.778693\n",
      "          1.0   0.136081  0.077760  0.116641  99.669518\n",
      "NO2       0.0   1.067479  1.081762  1.084160  96.766600\n",
      "          1.0   0.194401  0.058320  0.077760  99.669518\n",
      "NO        0.0   1.073109  1.059555  1.085515  96.781821\n",
      "          1.0   0.116641  0.097201  0.136081  99.650078\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Your pollutant NetCDF files\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "results_counts = {}\n",
    "results_pct = {}\n",
    "\n",
    "for pollutant, filepath in files.items():\n",
    "    print(f\"Processing {pollutant}...\")\n",
    "\n",
    "    # Open dataset\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    # Change \"Mean\" if variable name differs\n",
    "    df = ds[\"Mean\"].to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = ds[\"fire_binary_Italy\"].to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Global quartiles (all days together)\n",
    "    quantiles = df[\"pollutant\"].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "\n",
    "    # Assign quartile\n",
    "    def assign_quartile(x):\n",
    "        if x <= quantiles[0.25]:\n",
    "            return \"Q1\"\n",
    "        elif x <= quantiles[0.5]:\n",
    "            return \"Q2\"\n",
    "        elif x <= quantiles[0.75]:\n",
    "            return \"Q3\"\n",
    "        else:\n",
    "            return \"Q4\"\n",
    "\n",
    "    df[\"quartile\"] = df[\"pollutant\"].apply(assign_quartile)\n",
    "\n",
    "    # Counts & percentages\n",
    "    summary_counts = df.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    results_counts[pollutant] = summary_counts\n",
    "    results_pct[pollutant] = summary_pct\n",
    "\n",
    "# Combine into big tables\n",
    "counts_table = pd.concat(results_counts, names=[\"Pollutant\", \"Fire\"])\n",
    "pct_table = pd.concat(results_pct, names=[\"Pollutant\", \"Fire\"])\n",
    "\n",
    "print(\"\\nCounts of days in each quartile by pollutant & fire status:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages of days in each quartile by pollutant & fire status:\")\n",
    "print(pct_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d57b0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CO...\n",
      "Processing PM2.5...\n",
      "Processing PM10...\n",
      "Processing NO2...\n",
      "Processing NO...\n",
      "\n",
      "Counts of days in each quartile by pollutant & fire status:\n",
      "quartile           Q1     Q2     Q3      Q4\n",
      "Pollutant Fire                             \n",
      "CO        0.0   11016  11245  11053  966247\n",
      "          1.0      87     84     88    4680\n",
      "PM2.5     0.0   10991  11374  11075  966121\n",
      "          1.0      84    105     77    4673\n",
      "PM10      0.0   11041  11318  11033  966169\n",
      "          1.0      86     97     85    4671\n",
      "NO2       0.0   11081  11005  11129  966346\n",
      "          1.0      81     92     86    4680\n",
      "NO        0.0   11124  11104  11107  966226\n",
      "          1.0      82     86     90    4681\n",
      "\n",
      "Percentages of days in each quartile by pollutant & fire status:\n",
      "quartile              Q1        Q2        Q3         Q4\n",
      "Pollutant Fire                                         \n",
      "CO        0.0   1.102084  1.124994  1.105785  96.667137\n",
      "          1.0   1.761490  1.700749  1.781737  94.756023\n",
      "PM2.5     0.0   1.099583  1.137900  1.107986  96.654531\n",
      "          1.0   1.700749  2.125936  1.559020  94.614294\n",
      "PM10      0.0   1.104585  1.132297  1.103785  96.659333\n",
      "          1.0   1.741243  1.963960  1.720996  94.573800\n",
      "NO2       0.0   1.108587  1.100983  1.113389  96.677041\n",
      "          1.0   1.640008  1.862725  1.741243  94.756023\n",
      "NO        0.0   1.112889  1.110888  1.111188  96.665036\n",
      "          1.0   1.660255  1.741243  1.822231  94.776271\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Your pollutant NetCDF files\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "results_counts = {}\n",
    "results_pct = {}\n",
    "\n",
    "for pollutant, filepath in files.items():\n",
    "    print(f\"Processing {pollutant}...\")\n",
    "\n",
    "    # Open dataset\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    # Change \"Mean\" if variable name differs\n",
    "    df = ds[\"Mean\"].to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = ds[\"fire_binary_Spain\"].to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Global quartiles (all days together)\n",
    "    quantiles = df[\"pollutant\"].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "\n",
    "    # Assign quartile\n",
    "    def assign_quartile(x):\n",
    "        if x <= quantiles[0.25]:\n",
    "            return \"Q1\"\n",
    "        elif x <= quantiles[0.5]:\n",
    "            return \"Q2\"\n",
    "        elif x <= quantiles[0.75]:\n",
    "            return \"Q3\"\n",
    "        else:\n",
    "            return \"Q4\"\n",
    "\n",
    "    df[\"quartile\"] = df[\"pollutant\"].apply(assign_quartile)\n",
    "\n",
    "    # Counts & percentages\n",
    "    summary_counts = df.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    results_counts[pollutant] = summary_counts\n",
    "    results_pct[pollutant] = summary_pct\n",
    "\n",
    "# Combine into big tables\n",
    "counts_table = pd.concat(results_counts, names=[\"Pollutant\", \"Fire\"])\n",
    "pct_table = pd.concat(results_pct, names=[\"Pollutant\", \"Fire\"])\n",
    "\n",
    "print(\"\\nCounts of days in each quartile by pollutant & fire status:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages of days in each quartile by pollutant & fire status:\")\n",
    "print(pct_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5167fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CO...\n",
      "Processing PM2.5...\n",
      "Processing PM10...\n",
      "Processing NO2...\n",
      "Processing NO...\n",
      "\n",
      "Counts of days in each quartile by pollutant & fire status:\n",
      "quartile          Q1    Q2    Q3      Q4\n",
      "Pollutant Fire                          \n",
      "CO        0.0   4929  4764  4946  648445\n",
      "          1.0     15    13    16    3860\n",
      "PM2.5     0.0   4795  5050  5108  648131\n",
      "          1.0     11    23    16    3854\n",
      "PM10      0.0   4798  5040  5084  648162\n",
      "          1.0     13    20    17    3854\n",
      "NO2       0.0   4758  5003  5058  648265\n",
      "          1.0     12    20    15    3857\n",
      "NO        0.0   4789  4957  5103  648235\n",
      "          1.0     15    12    20    3857\n",
      "\n",
      "Percentages of days in each quartile by pollutant & fire status:\n",
      "quartile              Q1        Q2        Q3         Q4\n",
      "Pollutant Fire                                         \n",
      "CO        0.0   0.743345  0.718461  0.745909  97.792286\n",
      "          1.0   0.384221  0.332992  0.409836  98.872951\n",
      "PM2.5     0.0   0.723136  0.761593  0.770340  97.744931\n",
      "          1.0   0.281762  0.589139  0.409836  98.719262\n",
      "PM10      0.0   0.723589  0.760085  0.766720  97.749606\n",
      "          1.0   0.332992  0.512295  0.435451  98.719262\n",
      "NO2       0.0   0.717556  0.754505  0.762799  97.765140\n",
      "          1.0   0.307377  0.512295  0.384221  98.796107\n",
      "NO        0.0   0.722231  0.747567  0.769586  97.760616\n",
      "          1.0   0.384221  0.307377  0.512295  98.796107\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Your pollutant NetCDF files\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "results_counts = {}\n",
    "results_pct = {}\n",
    "\n",
    "for pollutant, filepath in files.items():\n",
    "    print(f\"Processing {pollutant}...\")\n",
    "\n",
    "    # Open dataset\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    # Change \"Mean\" if variable name differs\n",
    "    df = ds[\"Mean\"].to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = ds[\"fire_binary_Greece\"].to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Global quartiles (all days together)\n",
    "    quantiles = df[\"pollutant\"].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "\n",
    "    # Assign quartile\n",
    "    def assign_quartile(x):\n",
    "        if x <= quantiles[0.25]:\n",
    "            return \"Q1\"\n",
    "        elif x <= quantiles[0.5]:\n",
    "            return \"Q2\"\n",
    "        elif x <= quantiles[0.75]:\n",
    "            return \"Q3\"\n",
    "        else:\n",
    "            return \"Q4\"\n",
    "\n",
    "    df[\"quartile\"] = df[\"pollutant\"].apply(assign_quartile)\n",
    "\n",
    "    # Counts & percentages\n",
    "    summary_counts = df.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    results_counts[pollutant] = summary_counts\n",
    "    results_pct[pollutant] = summary_pct\n",
    "\n",
    "# Combine into big tables\n",
    "counts_table = pd.concat(results_counts, names=[\"Pollutant\", \"Fire\"])\n",
    "pct_table = pd.concat(results_pct, names=[\"Pollutant\", \"Fire\"])\n",
    "\n",
    "print(\"\\nCounts of days in each quartile by pollutant & fire status:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages of days in each quartile by pollutant & fire status:\")\n",
    "print(pct_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fd26f",
   "metadata": {},
   "source": [
    "Pearson correlation performed between meteorological variables and air pollutants, for all days and every label established"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55ce93c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All days: 8036\n",
      "NFD: 6302\n",
      "Day1: 0\n",
      "Day2: 0\n",
      "Day3: 0\n",
      "Day4: 0\n",
      "Day5: 0\n",
      "       All_days  NFD  Day0  Day1  Day2  Day3  Day4  Day5\n",
      "CO          NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "PM2.5       NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "PM10        NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "NO2         NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "NO          NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- Paths ---\n",
    "wind_folder = r\"D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\"\n",
    "pollutants = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "# --- Load and combine all wind speed files ---\n",
    "wind_files = sorted(glob.glob(os.path.join(wind_folder, \"*.nc\")))\n",
    "wind_list = []\n",
    "\n",
    "for f in wind_files:\n",
    "    ds = xr.open_dataset(f)\n",
    "    ds = ds.sel(latitude=slice(34,42), longitude=slice(19,29))  # Greece subset\n",
    "    # Daily mean using 'valid_time'\n",
    "    wind_daily = ds['wind_speed'].resample(valid_time='1D').mean(dim='valid_time')\n",
    "    # Spatial mean\n",
    "    wind_avg = wind_daily.mean(dim=['latitude','longitude'])\n",
    "    wind_list.append(wind_avg)\n",
    "\n",
    "wind_all = xr.concat(wind_list, dim='valid_time')\n",
    "wind_series = pd.Series(wind_all.values, index=pd.to_datetime(wind_all['valid_time'].values))\n",
    "\n",
    "# --- Load pollutant data and fire labels ---\n",
    "poll_data = {}\n",
    "fire_labels = None\n",
    "\n",
    "for name, path in pollutants.items():\n",
    "    ds = xr.open_dataset(path)\n",
    "    # Daily mean over region\n",
    "    data_avg = ds['Mean'].mean(dim=['latitude','longitude']).values\n",
    "    poll_data[name] = pd.Series(data_avg, index=pd.to_datetime(ds['time'].values))\n",
    "    \n",
    "    # Fire labels (only once)\n",
    "    if fire_labels is None:\n",
    "        labels_avg = ds['fire_label_Portugal'].mean(dim=['latitude','longitude']).values\n",
    "        fire_labels = pd.Series(labels_avg, index=pd.to_datetime(ds['time'].values))\n",
    "\n",
    "# --- Combine into DataFrame ---\n",
    "df = pd.DataFrame(poll_data)\n",
    "df['wind_speed'] = wind_series\n",
    "df = df.loc[df.index.intersection(fire_labels.index)]  # align indices\n",
    "\n",
    "# --- Define subsets ---\n",
    "def get_subset(label):\n",
    "    return fire_labels[fire_labels==label].index\n",
    "\n",
    "# --- Function to compute correlation with safety check ---\n",
    "def compute_corr(idx):\n",
    "    sub = df.loc[idx]\n",
    "    corr_dict = {}\n",
    "    for col in df.columns[:-1]:  # pollutants only\n",
    "        if len(sub) < 2:\n",
    "            corr_dict[col] = np.nan  # Not enough data\n",
    "        else:\n",
    "            r, _ = pearsonr(sub['wind_speed'], sub[col])\n",
    "            corr_dict[col] = r\n",
    "    return pd.Series(corr_dict, name='wind_speed')\n",
    "\n",
    "# --- Print subset sizes for info ---\n",
    "print(\"All days:\", len(df))\n",
    "print(\"NFD:\", len(get_subset(0)))\n",
    "for i in range(1,6):\n",
    "    print(f\"Day{i}:\", len(get_subset(i)))\n",
    "\n",
    "# --- Build full correlation table ---\n",
    "all_days = compute_corr(df.index)\n",
    "nfd = compute_corr(get_subset(0))\n",
    "day_tables = [compute_corr(get_subset(i)) for i in range(1,6)]\n",
    "\n",
    "day_tables = [compute_corr(get_subset(i)) for i in range(1,7)]  # 1 to 6 inclusive\n",
    "full_table = pd.concat([all_days, nfd] + day_tables, axis=1)\n",
    "full_table.columns = ['All_days', 'NFD', 'Day0','Day1','Day2','Day3','Day4','Day5']\n",
    "\n",
    "print(full_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53094490",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 99\u001b[0m\n\u001b[0;32m     85\u001b[0m         corrs_by_label[label] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([np\u001b[38;5;241m.\u001b[39mnan]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCO\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPM2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPM10\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# 5. Build final correlation table\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Build final correlation table\u001b[39;00m\n\u001b[0;32m     91\u001b[0m corr_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[0;32m     92\u001b[0m     [all_days,\n\u001b[0;32m     93\u001b[0m      corrs_by_label[\u001b[38;5;241m0\u001b[39m],  \u001b[38;5;66;03m# NFD\u001b[39;00m\n\u001b[0;32m     94\u001b[0m      corrs_by_label[\u001b[38;5;241m1\u001b[39m],  \u001b[38;5;66;03m# Day0\u001b[39;00m\n\u001b[0;32m     95\u001b[0m      corrs_by_label[\u001b[38;5;241m2\u001b[39m],  \u001b[38;5;66;03m# Day1\u001b[39;00m\n\u001b[0;32m     96\u001b[0m      corrs_by_label[\u001b[38;5;241m3\u001b[39m],  \u001b[38;5;66;03m# Day2\u001b[39;00m\n\u001b[0;32m     97\u001b[0m      corrs_by_label[\u001b[38;5;241m4\u001b[39m],  \u001b[38;5;66;03m# Day3\u001b[39;00m\n\u001b[0;32m     98\u001b[0m      corrs_by_label[\u001b[38;5;241m5\u001b[39m],  \u001b[38;5;66;03m# Day4\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m      \u001b[43mcorrs_by_label\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m], \u001b[38;5;66;03m# Day5\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m corr_table\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll_days\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNFD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay5\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(corr_table)\n",
      "\u001b[1;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load wind dataset (hourly, 0.25° grid)\n",
    "# -------------------------\n",
    "wind_folder = r\"D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\"\n",
    "wind_files = sorted(glob.glob(os.path.join(wind_folder, \"*.nc\")))\n",
    "\n",
    "ds_wind = xr.open_mfdataset(wind_files, combine=\"by_coords\")\n",
    "\n",
    "# Detect correct time coordinate\n",
    "time_coord = None\n",
    "for cand in [\"time\", \"valid_time\", \"date\", \"time_counter\"]:\n",
    "    if cand in ds_wind.dims or cand in ds_wind.coords:\n",
    "        time_coord = cand\n",
    "        break\n",
    "if time_coord is None:\n",
    "    raise ValueError(\"❌ Could not find a time coordinate in wind dataset\")\n",
    "\n",
    "# Regrid 0.25° → 0.75° (3x3 bins)\n",
    "wind_coarse = ds_wind.coarsen(latitude=3, longitude=3, boundary=\"trim\").mean()\n",
    "\n",
    "# Hourly → daily mean\n",
    "wind_daily = wind_coarse[\"wind_speed\"].resample({time_coord: \"1D\"}).mean()\n",
    "\n",
    "# Regional average (Portugal)\n",
    "wind_series = wind_daily.mean(dim=[\"latitude\", \"longitude\"]).to_pandas()\n",
    "wind_series.name = \"wind_speed\"\n",
    "\n",
    "# -------------------------\n",
    "# 2. Load pollutant datasets (already daily + fire labels)\n",
    "# -------------------------\n",
    "pollutants_files = {\n",
    "    \"CO\":   r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\":r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\":  r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\":   r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\",\n",
    "}\n",
    "\n",
    "pollutants = {}\n",
    "fire_labels = None\n",
    "\n",
    "for pol, path in pollutants_files.items():\n",
    "    ds = xr.open_dataset(path)\n",
    "\n",
    "    # ✅ Take spatial mean over lat/lon to get a single daily series\n",
    "    pol_series = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"]).to_pandas()\n",
    "    pol_series.name = pol\n",
    "    pollutants[pol] = pol_series\n",
    "\n",
    "    # ✅ Fire labels: take spatial mean and round (they should already be consistent across grid)\n",
    "    if fire_labels is None:\n",
    "        label_var = [v for v in ds.data_vars if \"fire_label\" in v][0]\n",
    "        fire_labels = ds[label_var].mean(dim=[\"latitude\", \"longitude\"]).round().astype(int).to_pandas()\n",
    "\n",
    "# -------------------------\n",
    "# 3. Combine into one dataframe\n",
    "# -------------------------\n",
    "df = pd.concat(pollutants.values(), axis=1)\n",
    "df[\"wind_speed\"] = wind_series\n",
    "df[\"fire_label\"] = fire_labels\n",
    "df = df.dropna()\n",
    "\n",
    "# -------------------------\n",
    "# 4. Correlation helper\n",
    "# -------------------------\n",
    "def compute_corr(subset):\n",
    "    \"\"\"Return correlation between wind_speed and all pollutants.\"\"\"\n",
    "    return subset.corr().loc[\"wind_speed\", [\"CO\", \"NO\", \"NO2\", \"PM2.5\", \"PM10\"]]\n",
    "\n",
    "# All data (no filtering)\n",
    "all_days = compute_corr(df)\n",
    "\n",
    "# Label-based subsets\n",
    "corrs_by_label = {}\n",
    "for label in range(6):  # 0 = NFD, 1=Day0 ... 5=Day5\n",
    "    subset = df[df[\"fire_label\"] == label]\n",
    "    if not subset.empty:\n",
    "        corrs_by_label[label] = compute_corr(subset)\n",
    "    else:\n",
    "        corrs_by_label[label] = pd.Series([np.nan]*5, index=[\"CO\",\"NO\",\"NO2\",\"PM2.5\",\"PM10\"])\n",
    "\n",
    "# -------------------------\n",
    "# 5. Build final correlation table\n",
    "# -------------------------\n",
    "# Build final correlation table\n",
    "corr_table = pd.concat(\n",
    "    [all_days,\n",
    "     corrs_by_label[0],  # NFD\n",
    "     corrs_by_label[1],  # Day0\n",
    "     corrs_by_label[2],  # Day1\n",
    "     corrs_by_label[3],  # Day2\n",
    "     corrs_by_label[4],  # Day3\n",
    "     corrs_by_label[5],  # Day4\n",
    "     corrs_by_label[6]], # Day5\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "corr_table.columns = [\"All_days\", \"NFD\", \"Day0\", \"Day1\", \"Day2\", \"Day3\", \"Day4\", \"Day5\"]\n",
    "\n",
    "print(corr_table)\n",
    "\n",
    "# Save to Excel\n",
    "corr_table.to_excel(r\"D:\\IPMA\\Results\\wind_pollutant_correlation_Portugal.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ad764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20239a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
