{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5837e9",
   "metadata": {},
   "source": [
    "mean +- standard error of mean of pollutants on day without fire, with fire and up to 5 days after fire outbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52216297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Portugal'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000    \n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Portugal):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec16065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Italy'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Italy):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5400942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Spain'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Spain):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff276096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Greece'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Greece):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e2468",
   "metadata": {},
   "source": [
    "Divide daily concentrations of pollutants into quartiles Q1 (lowest), Q2, Q3 and Q4 (highest) for days when fires occurred and days they did not - Assess the impact of fire events on the concentration of air pollutants. Calculation of percentage of days (non-wildfire and wildfire) in each of the four qaurtiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f7947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\4039012915.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\4039012915.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\4039012915.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\4039012915.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts table:\n",
      "quartile  fire   Q1   Q2   Q3   Q4 pollutant\n",
      "0          0.0  385  384  384  384        CO\n",
      "1          1.0   36   36   36   36        CO\n",
      "2          0.0  385  384  384  384     PM2.5\n",
      "3          1.0   36   36   36   36     PM2.5\n",
      "4          0.0  385  384  384  384      PM10\n",
      "5          1.0   36   36   36   36      PM10\n",
      "6          0.0  385  384  384  384       NO2\n",
      "7          1.0   36   36   36   36       NO2\n",
      "8          0.0  385  384  384  384        NO\n",
      "9          1.0   36   36   36   36        NO\n",
      "\n",
      "Percentages table:\n",
      "quartile  fire         Q1         Q2         Q3         Q4 pollutant\n",
      "0          0.0  25.048796  24.983735  24.983735  24.983735        CO\n",
      "1          1.0  25.000000  25.000000  25.000000  25.000000        CO\n",
      "2          0.0  25.048796  24.983735  24.983735  24.983735     PM2.5\n",
      "3          1.0  25.000000  25.000000  25.000000  25.000000     PM2.5\n",
      "4          0.0  25.048796  24.983735  24.983735  24.983735      PM10\n",
      "5          1.0  25.000000  25.000000  25.000000  25.000000      PM10\n",
      "6          0.0  25.048796  24.983735  24.983735  24.983735       NO2\n",
      "7          1.0  25.000000  25.000000  25.000000  25.000000       NO2\n",
      "8          0.0  25.048796  24.983735  24.983735  24.983735        NO\n",
      "9          1.0  25.000000  25.000000  25.000000  25.000000        NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\4039012915.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# --- List of pollutant files (example with CO and PM2.5) ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if different variable name\n",
    "    fire_flag = ds[\"fire_binary_Portugal\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Drop NaNs before analysis\n",
    "    df = df.dropna(subset=[\"pollutant\", \"fire\"])\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # Summary: counts\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Summary: percentages\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0f95ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\2593490842.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\2593490842.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\2593490842.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\2593490842.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts table:\n",
      "quartile  fire     Q1     Q2     Q3     Q4 pollutant\n",
      "0          0.0  10282  10282  10281  10282        CO\n",
      "1          1.0      6      6      6      6        CO\n",
      "2          0.0  10282  10282  10281  10282     PM2.5\n",
      "3          1.0      6      6      6      6     PM2.5\n",
      "4          0.0  10282  10281  10281  10282      PM10\n",
      "5          1.0      6      6      6      6      PM10\n",
      "6          0.0  10282  10282  10281  10282       NO2\n",
      "7          1.0      6      6      6      6       NO2\n",
      "8          0.0  10277  10277  10277  10277        NO\n",
      "9          1.0      6      6      6      6        NO\n",
      "\n",
      "Percentages table:\n",
      "quartile  fire         Q1         Q2         Q3         Q4 pollutant\n",
      "0          0.0  25.000608  25.000608  24.998176  25.000608        CO\n",
      "1          1.0  25.000000  25.000000  25.000000  25.000000        CO\n",
      "2          0.0  25.000608  25.000608  24.998176  25.000608     PM2.5\n",
      "3          1.0  25.000000  25.000000  25.000000  25.000000     PM2.5\n",
      "4          0.0  25.001216  24.998784  24.998784  25.001216      PM10\n",
      "5          1.0  25.000000  25.000000  25.000000  25.000000      PM10\n",
      "6          0.0  25.000608  25.000608  24.998176  25.000608       NO2\n",
      "7          1.0  25.000000  25.000000  25.000000  25.000000       NO2\n",
      "8          0.0  25.000000  25.000000  25.000000  25.000000        NO\n",
      "9          1.0  25.000000  25.000000  25.000000  25.000000        NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\2593490842.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "pollutant",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fire",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "quartile",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "ref": "906dcfa7-fd61-4283-83b7-0667362ab137",
       "rows": [
        [
         "783147",
         "35.25",
         "12.0",
         "2013-01-03 00:00:00",
         "0.01189981190421717",
         "1.0",
         "Q1"
        ],
        [
         "791598",
         "35.25",
         "12.75",
         "2014-02-22 00:00:00",
         "0.03256367246146269",
         "1.0",
         "Q1"
        ],
        [
         "2884858",
         "38.25",
         "12.75",
         "2024-10-27 00:00:00",
         "0.07232773303985596",
         "1.0",
         "Q1"
        ],
        [
         "3360466",
         "39.0",
         "9.0",
         "2006-11-19 00:00:00",
         "0.0861606767994354",
         "1.0",
         "Q1"
        ],
        [
         "3362877",
         "39.0",
         "9.0",
         "2013-06-26 00:00:00",
         "0.27875527979493875",
         "1.0",
         "Q2"
        ],
        [
         "3427611",
         "39.0",
         "15.0",
         "2014-09-15 00:00:00",
         "0.02280023366029789",
         "1.0",
         "Q1"
        ],
        [
         "3874431",
         "39.75",
         "8.25",
         "2005-12-15 00:00:00",
         "0.5932214165386474",
         "1.0",
         "Q3"
        ],
        [
         "4397537",
         "40.5",
         "8.25",
         "2008-01-20 00:00:00",
         "0.8047063572681804",
         "1.0",
         "Q3"
        ],
        [
         "4455978",
         "40.5",
         "13.5",
         "2014-01-17 00:00:00",
         "0.4448507062370881",
         "1.0",
         "Q2"
        ],
        [
         "4475802",
         "40.5",
         "15.0",
         "2024-04-26 00:00:00",
         "0.1646437644958496",
         "1.0",
         "Q2"
        ],
        [
         "4978767",
         "41.25",
         "13.5",
         "2015-04-11 00:00:00",
         "1.549320077576369",
         "1.0",
         "Q4"
        ],
        [
         "5464781",
         "42.0",
         "10.5",
         "2003-10-29 00:00:00",
         "0.046365072304790644",
         "1.0",
         "Q1"
        ],
        [
         "5476343",
         "42.0",
         "11.25",
         "2013-06-24 00:00:00",
         "0.49431534341525296",
         "1.0",
         "Q3"
        ],
        [
         "5481291",
         "42.0",
         "12.0",
         "2005-01-09 00:00:00",
         "5.958200458735877",
         "1.0",
         "Q4"
        ],
        [
         "5506380",
         "42.0",
         "14.25",
         "2007-09-17 00:00:00",
         "0.8114901240451224",
         "1.0",
         "Q3"
        ],
        [
         "5511970",
         "42.0",
         "14.25",
         "2023-01-06 00:00:00",
         "8.694459915161133",
         "1.0",
         "Q4"
        ],
        [
         "5512222",
         "42.0",
         "14.25",
         "2023-09-15 00:00:00",
         "0.5814429521560669",
         "1.0",
         "Q3"
        ],
        [
         "5514829",
         "42.0",
         "15.0",
         "2008-11-03 00:00:00",
         "5.560109473193307",
         "1.0",
         "Q4"
        ],
        [
         "5514831",
         "42.0",
         "15.0",
         "2008-11-05 00:00:00",
         "0.9983975671973326",
         "1.0",
         "Q3"
        ],
        [
         "6527196",
         "43.5",
         "12.0",
         "2008-05-18 00:00:00",
         "0.2023622332506506",
         "1.0",
         "Q2"
        ],
        [
         "7044206",
         "44.25",
         "11.25",
         "2015-10-15 00:00:00",
         "1.9308232756219355",
         "1.0",
         "Q4"
        ],
        [
         "7580978",
         "45.0",
         "12.75",
         "2011-04-19 00:00:00",
         "0.2619106755257848",
         "1.0",
         "Q2"
        ],
        [
         "8608829",
         "46.5",
         "11.25",
         "2009-03-23 00:00:00",
         "0.2907897045234178",
         "1.0",
         "Q2"
        ],
        [
         "8628786",
         "46.5",
         "12.75",
         "2019-11-11 00:00:00",
         "2.1766963970337674",
         "1.0",
         "Q4"
        ],
        [
         "779902",
         "35.25",
         "12.0",
         "2004-02-15 00:00:00",
         "0.2309405554488297",
         "0.0",
         "Q2"
        ],
        [
         "779903",
         "35.25",
         "12.0",
         "2004-02-16 00:00:00",
         "0.23755124091860716",
         "0.0",
         "Q2"
        ],
        [
         "779968",
         "35.25",
         "12.0",
         "2004-04-21 00:00:00",
         "0.15861771003205388",
         "0.0",
         "Q2"
        ],
        [
         "780032",
         "35.25",
         "12.0",
         "2004-06-24 00:00:00",
         "0.10885328795504579",
         "0.0",
         "Q1"
        ],
        [
         "780098",
         "35.25",
         "12.0",
         "2004-08-29 00:00:00",
         "0.0",
         "0.0",
         "Q1"
        ],
        [
         "780099",
         "35.25",
         "12.0",
         "2004-08-30 00:00:00",
         "0.0",
         "0.0",
         "Q1"
        ],
        [
         "780100",
         "35.25",
         "12.0",
         "2004-08-31 00:00:00",
         "0.04113838698295248",
         "0.0",
         "Q1"
        ],
        [
         "780101",
         "35.25",
         "12.0",
         "2004-09-01 00:00:00",
         "0.006502228820981192",
         "0.0",
         "Q1"
        ],
        [
         "780162",
         "35.25",
         "12.0",
         "2004-11-01 00:00:00",
         "0.0903991719436042",
         "0.0",
         "Q1"
        ],
        [
         "780163",
         "35.25",
         "12.0",
         "2004-11-02 00:00:00",
         "0.022870783766380243",
         "0.0",
         "Q1"
        ],
        [
         "780164",
         "35.25",
         "12.0",
         "2004-11-03 00:00:00",
         "0.021026471966207248",
         "0.0",
         "Q1"
        ],
        [
         "780165",
         "35.25",
         "12.0",
         "2004-11-04 00:00:00",
         "0.031311887394058435",
         "0.0",
         "Q1"
        ],
        [
         "780166",
         "35.25",
         "12.0",
         "2004-11-05 00:00:00",
         "0.03345050189733406",
         "0.0",
         "Q1"
        ],
        [
         "780167",
         "35.25",
         "12.0",
         "2004-11-06 00:00:00",
         "0.045954795995768564",
         "0.0",
         "Q1"
        ],
        [
         "780168",
         "35.25",
         "12.0",
         "2004-11-07 00:00:00",
         "0.04399506876990551",
         "0.0",
         "Q1"
        ],
        [
         "780222",
         "35.25",
         "12.0",
         "2004-12-31 00:00:00",
         "0.037952587361584876",
         "0.0",
         "Q1"
        ],
        [
         "780223",
         "35.25",
         "12.0",
         "2005-01-01 00:00:00",
         "0.07158266867810906",
         "0.0",
         "Q1"
        ],
        [
         "780224",
         "35.25",
         "12.0",
         "2005-01-02 00:00:00",
         "0.14719238516402486",
         "0.0",
         "Q2"
        ],
        [
         "780229",
         "35.25",
         "12.0",
         "2005-01-07 00:00:00",
         "0.06132874638702674",
         "0.0",
         "Q1"
        ],
        [
         "780231",
         "35.25",
         "12.0",
         "2005-01-09 00:00:00",
         "0.0470962338824403",
         "0.0",
         "Q1"
        ],
        [
         "780232",
         "35.25",
         "12.0",
         "2005-01-10 00:00:00",
         "0.012248686861408236",
         "0.0",
         "Q1"
        ],
        [
         "780233",
         "35.25",
         "12.0",
         "2005-01-11 00:00:00",
         "0.012243135656009475",
         "0.0",
         "Q1"
        ],
        [
         "780234",
         "35.25",
         "12.0",
         "2005-01-12 00:00:00",
         "0.05300730138902979",
         "0.0",
         "Q1"
        ],
        [
         "780287",
         "35.25",
         "12.0",
         "2005-03-06 00:00:00",
         "0.10828350015461297",
         "0.0",
         "Q1"
        ],
        [
         "780288",
         "35.25",
         "12.0",
         "2005-03-07 00:00:00",
         "0.1633876268745417",
         "0.0",
         "Q2"
        ],
        [
         "780289",
         "35.25",
         "12.0",
         "2005-03-08 00:00:00",
         "0.15687230106612712",
         "0.0",
         "Q2"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 41132
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>fire</th>\n",
       "      <th>quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>783147</th>\n",
       "      <td>35.25</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791598</th>\n",
       "      <td>35.25</td>\n",
       "      <td>12.75</td>\n",
       "      <td>2014-02-22</td>\n",
       "      <td>0.032564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884858</th>\n",
       "      <td>38.25</td>\n",
       "      <td>12.75</td>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>0.072328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360466</th>\n",
       "      <td>39.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2006-11-19</td>\n",
       "      <td>0.086161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362877</th>\n",
       "      <td>39.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>0.278755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143518</th>\n",
       "      <td>47.25</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>3.720558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143519</th>\n",
       "      <td>47.25</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>1.138191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143580</th>\n",
       "      <td>47.25</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>0.275044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143581</th>\n",
       "      <td>47.25</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>0.412056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143582</th>\n",
       "      <td>47.25</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>0.399969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41132 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude       time  pollutant  fire quartile\n",
       "783147      35.25      12.00 2013-01-03   0.011900   1.0       Q1\n",
       "791598      35.25      12.75 2014-02-22   0.032564   1.0       Q1\n",
       "2884858     38.25      12.75 2024-10-27   0.072328   1.0       Q1\n",
       "3360466     39.00       9.00 2006-11-19   0.086161   1.0       Q1\n",
       "3362877     39.00       9.00 2013-06-26   0.278755   1.0       Q2\n",
       "...           ...        ...        ...        ...   ...      ...\n",
       "9143518     47.25      12.00 2021-01-12   3.720558   0.0       Q4\n",
       "9143519     47.25      12.00 2021-01-13   1.138191   0.0       Q3\n",
       "9143580     47.25      12.00 2021-03-15   0.275044   0.0       Q2\n",
       "9143581     47.25      12.00 2021-03-16   0.412056   0.0       Q3\n",
       "9143582     47.25      12.00 2021-03-17   0.399969   0.0       Q3\n",
       "\n",
       "[41132 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# --- List of pollutant files (example with CO and PM2.5) ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if different variable name\n",
    "    fire_flag = ds[\"fire_binary_Italy\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Drop NaNs before analysis\n",
    "    df = df.dropna(subset=[\"pollutant\", \"fire\"])\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # Summary: counts\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Summary: percentages\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n",
    "\n",
    "df_quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24d5c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\366744304.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\366744304.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\366744304.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\366744304.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts table:\n",
      "quartile  fire     Q1     Q2     Q3     Q4 pollutant\n",
      "0          0.0  11124  11123  11123  11123        CO\n",
      "1          1.0     88     87     87     87        CO\n",
      "2          0.0  11124  11123  11123  11123     PM2.5\n",
      "3          1.0     88     87     87     87     PM2.5\n",
      "4          0.0  11124  11123  11123  11123      PM10\n",
      "5          1.0     88     87     87     87      PM10\n",
      "6          0.0  11124  11123  11123  11123       NO2\n",
      "7          1.0     88     87     87     87       NO2\n",
      "8          0.0  11123  11122  11122  11123        NO\n",
      "9          1.0     88     87     87     87        NO\n",
      "\n",
      "Percentages table:\n",
      "quartile  fire         Q1         Q2         Q3         Q4 pollutant\n",
      "0          0.0  25.001686  24.999438  24.999438  24.999438        CO\n",
      "1          1.0  25.214900  24.928367  24.928367  24.928367        CO\n",
      "2          0.0  25.001686  24.999438  24.999438  24.999438     PM2.5\n",
      "3          1.0  25.214900  24.928367  24.928367  24.928367     PM2.5\n",
      "4          0.0  25.001686  24.999438  24.999438  24.999438      PM10\n",
      "5          1.0  25.214900  24.928367  24.928367  24.928367      PM10\n",
      "6          0.0  25.001686  24.999438  24.999438  24.999438       NO2\n",
      "7          1.0  25.214900  24.928367  24.928367  24.928367       NO2\n",
      "8          0.0  25.001124  24.998876  24.998876  25.001124        NO\n",
      "9          1.0  25.214900  24.928367  24.928367  24.928367        NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\366744304.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# --- List of pollutant files (example with CO and PM2.5) ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if different variable name\n",
    "    fire_flag = ds[\"fire_binary_Spain\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Drop NaNs before analysis\n",
    "    df = df.dropna(subset=[\"pollutant\", \"fire\"])\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # Summary: counts\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Summary: percentages\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed3a165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\922486095.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\922486095.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\922486095.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\922486095.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts table:\n",
      "quartile  fire    Q1    Q2    Q3    Q4 pollutant\n",
      "0          0.0  4955  4954  4954  4954        CO\n",
      "1          1.0    15    14    14    15        CO\n",
      "2          0.0  4955  4954  4954  4954     PM2.5\n",
      "3          1.0    15    14    14    15     PM2.5\n",
      "4          0.0  4953  4952  4952  4952      PM10\n",
      "5          1.0    15    14    14    15      PM10\n",
      "6          0.0  4955  4954  4954  4954       NO2\n",
      "7          1.0    15    14    14    15       NO2\n",
      "8          0.0  4953  4953  4953  4953        NO\n",
      "9          1.0    15    14    14    15        NO\n",
      "\n",
      "Percentages table:\n",
      "quartile  fire         Q1         Q2         Q3         Q4 pollutant\n",
      "0          0.0  25.003785  24.998738  24.998738  24.998738        CO\n",
      "1          1.0  25.862069  24.137931  24.137931  25.862069        CO\n",
      "2          0.0  25.003785  24.998738  24.998738  24.998738     PM2.5\n",
      "3          1.0  25.862069  24.137931  24.137931  25.862069     PM2.5\n",
      "4          0.0  25.003786  24.998738  24.998738  24.998738      PM10\n",
      "5          1.0  25.862069  24.137931  24.137931  25.862069      PM10\n",
      "6          0.0  25.003785  24.998738  24.998738  24.998738       NO2\n",
      "7          1.0  25.862069  24.137931  24.137931  25.862069       NO2\n",
      "8          0.0  25.000000  25.000000  25.000000  25.000000        NO\n",
      "9          1.0  25.862069  24.137931  24.137931  25.862069        NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_21496\\922486095.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# --- List of pollutant files (example with CO and PM2.5) ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if different variable name\n",
    "    fire_flag = ds[\"fire_binary_Greece\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Drop NaNs before analysis\n",
    "    df = df.dropna(subset=[\"pollutant\", \"fire\"])\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # Summary: counts\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Summary: percentages\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f1ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf28794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Your pollutant NetCDF files\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "results_counts = {}\n",
    "results_pct = {}\n",
    "\n",
    "for pollutant, filepath in files.items():\n",
    "    print(f\"Processing {pollutant}...\")\n",
    "\n",
    "    # Open dataset\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    # Change \"Mean\" if variable name differs\n",
    "    df = ds[\"Mean\"].to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = ds[\"fire_binary_Portugal\"].to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Global quartiles (all days together)\n",
    "    quantiles = df[\"pollutant\"].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "\n",
    "    # Assign quartile\n",
    "    def assign_quartile(x):\n",
    "        if x <= quantiles[0.25]:\n",
    "            return \"Q1\"\n",
    "        elif x <= quantiles[0.5]:\n",
    "            return \"Q2\"\n",
    "        elif x <= quantiles[0.75]:\n",
    "            return \"Q3\"\n",
    "        else:\n",
    "            return \"Q4\"\n",
    "\n",
    "    df[\"quartile\"] = df[\"pollutant\"].apply(assign_quartile)\n",
    "\n",
    "    # Counts & percentages\n",
    "    summary_counts = df.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    results_counts[pollutant] = summary_counts\n",
    "    results_pct[pollutant] = summary_pct\n",
    "\n",
    "# Combine into big tables\n",
    "counts_table = pd.concat(results_counts, names=[\"Pollutant\", \"Fire\"])\n",
    "pct_table = pd.concat(results_pct, names=[\"Pollutant\", \"Fire\"])\n",
    "\n",
    "print(\"\\nCounts of days in each quartile by pollutant & fire status:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages of days in each quartile by pollutant & fire status:\")\n",
    "print(pct_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Your pollutant NetCDF files\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "results_counts = {}\n",
    "results_pct = {}\n",
    "\n",
    "for pollutant, filepath in files.items():\n",
    "    print(f\"Processing {pollutant}...\")\n",
    "\n",
    "    # Open dataset\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    # Change \"Mean\" if variable name differs\n",
    "    df = ds[\"Mean\"].to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = ds[\"fire_binary_Italy\"].to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Global quartiles (all days together)\n",
    "    quantiles = df[\"pollutant\"].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "\n",
    "    # Assign quartile\n",
    "    def assign_quartile(x):\n",
    "        if x <= quantiles[0.25]:\n",
    "            return \"Q1\"\n",
    "        elif x <= quantiles[0.5]:\n",
    "            return \"Q2\"\n",
    "        elif x <= quantiles[0.75]:\n",
    "            return \"Q3\"\n",
    "        else:\n",
    "            return \"Q4\"\n",
    "\n",
    "    df[\"quartile\"] = df[\"pollutant\"].apply(assign_quartile)\n",
    "\n",
    "    # Counts & percentages\n",
    "    summary_counts = df.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    results_counts[pollutant] = summary_counts\n",
    "    results_pct[pollutant] = summary_pct\n",
    "\n",
    "# Combine into big tables\n",
    "counts_table = pd.concat(results_counts, names=[\"Pollutant\", \"Fire\"])\n",
    "pct_table = pd.concat(results_pct, names=[\"Pollutant\", \"Fire\"])\n",
    "\n",
    "print(\"\\nCounts of days in each quartile by pollutant & fire status:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages of days in each quartile by pollutant & fire status:\")\n",
    "print(pct_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Your pollutant NetCDF files\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "results_counts = {}\n",
    "results_pct = {}\n",
    "\n",
    "for pollutant, filepath in files.items():\n",
    "    print(f\"Processing {pollutant}...\")\n",
    "\n",
    "    # Open dataset\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    # Change \"Mean\" if variable name differs\n",
    "    df = ds[\"Mean\"].to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = ds[\"fire_binary_Spain\"].to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Global quartiles (all days together)\n",
    "    quantiles = df[\"pollutant\"].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "\n",
    "    # Assign quartile\n",
    "    def assign_quartile(x):\n",
    "        if x <= quantiles[0.25]:\n",
    "            return \"Q1\"\n",
    "        elif x <= quantiles[0.5]:\n",
    "            return \"Q2\"\n",
    "        elif x <= quantiles[0.75]:\n",
    "            return \"Q3\"\n",
    "        else:\n",
    "            return \"Q4\"\n",
    "\n",
    "    df[\"quartile\"] = df[\"pollutant\"].apply(assign_quartile)\n",
    "\n",
    "    # Counts & percentages\n",
    "    summary_counts = df.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    results_counts[pollutant] = summary_counts\n",
    "    results_pct[pollutant] = summary_pct\n",
    "\n",
    "# Combine into big tables\n",
    "counts_table = pd.concat(results_counts, names=[\"Pollutant\", \"Fire\"])\n",
    "pct_table = pd.concat(results_pct, names=[\"Pollutant\", \"Fire\"])\n",
    "\n",
    "print(\"\\nCounts of days in each quartile by pollutant & fire status:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages of days in each quartile by pollutant & fire status:\")\n",
    "print(pct_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5167fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Your pollutant NetCDF files\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "results_counts = {}\n",
    "results_pct = {}\n",
    "\n",
    "for pollutant, filepath in files.items():\n",
    "    print(f\"Processing {pollutant}...\")\n",
    "\n",
    "    # Open dataset\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    # Change \"Mean\" if variable name differs\n",
    "    df = ds[\"Mean\"].to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = ds[\"fire_binary_Greece\"].to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Global quartiles (all days together)\n",
    "    quantiles = df[\"pollutant\"].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "\n",
    "    # Assign quartile\n",
    "    def assign_quartile(x):\n",
    "        if x <= quantiles[0.25]:\n",
    "            return \"Q1\"\n",
    "        elif x <= quantiles[0.5]:\n",
    "            return \"Q2\"\n",
    "        elif x <= quantiles[0.75]:\n",
    "            return \"Q3\"\n",
    "        else:\n",
    "            return \"Q4\"\n",
    "\n",
    "    df[\"quartile\"] = df[\"pollutant\"].apply(assign_quartile)\n",
    "\n",
    "    # Counts & percentages\n",
    "    summary_counts = df.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    results_counts[pollutant] = summary_counts\n",
    "    results_pct[pollutant] = summary_pct\n",
    "\n",
    "# Combine into big tables\n",
    "counts_table = pd.concat(results_counts, names=[\"Pollutant\", \"Fire\"])\n",
    "pct_table = pd.concat(results_pct, names=[\"Pollutant\", \"Fire\"])\n",
    "\n",
    "print(\"\\nCounts of days in each quartile by pollutant & fire status:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages of days in each quartile by pollutant & fire status:\")\n",
    "print(pct_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fd26f",
   "metadata": {},
   "source": [
    "Pearson correlation performed between meteorological variables and air pollutants, for all days and every label established"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- Paths ---\n",
    "wind_folder = r\"D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\"\n",
    "pollutants = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "# --- Load and combine all wind speed files ---\n",
    "wind_files = sorted(glob.glob(os.path.join(wind_folder, \"*.nc\")))\n",
    "wind_list = []\n",
    "\n",
    "for f in wind_files:\n",
    "    ds = xr.open_dataset(f)\n",
    "    ds = ds.sel(latitude=slice(34,42), longitude=slice(19,29))  # Greece subset\n",
    "    # Daily mean using 'valid_time'\n",
    "    wind_daily = ds['wind_speed'].resample(valid_time='1D').mean(dim='valid_time')\n",
    "    # Spatial mean\n",
    "    wind_avg = wind_daily.mean(dim=['latitude','longitude'])\n",
    "    wind_list.append(wind_avg)\n",
    "\n",
    "wind_all = xr.concat(wind_list, dim='valid_time')\n",
    "wind_series = pd.Series(wind_all.values, index=pd.to_datetime(wind_all['valid_time'].values))\n",
    "\n",
    "# --- Load pollutant data and fire labels ---\n",
    "poll_data = {}\n",
    "fire_labels = None\n",
    "\n",
    "for name, path in pollutants.items():\n",
    "    ds = xr.open_dataset(path)\n",
    "    # Daily mean over region\n",
    "    data_avg = ds['Mean'].mean(dim=['latitude','longitude']).values\n",
    "    poll_data[name] = pd.Series(data_avg, index=pd.to_datetime(ds['time'].values))\n",
    "    \n",
    "    # Fire labels (only once)\n",
    "    if fire_labels is None:\n",
    "        labels_avg = ds['fire_label_Portugal'].mean(dim=['latitude','longitude']).values\n",
    "        fire_labels = pd.Series(labels_avg, index=pd.to_datetime(ds['time'].values))\n",
    "\n",
    "# --- Combine into DataFrame ---\n",
    "df = pd.DataFrame(poll_data)\n",
    "df['wind_speed'] = wind_series\n",
    "df = df.loc[df.index.intersection(fire_labels.index)]  # align indices\n",
    "\n",
    "# --- Define subsets ---\n",
    "def get_subset(label):\n",
    "    return fire_labels[fire_labels==label].index\n",
    "\n",
    "# --- Function to compute correlation with safety check ---\n",
    "def compute_corr(idx):\n",
    "    sub = df.loc[idx]\n",
    "    corr_dict = {}\n",
    "    for col in df.columns[:-1]:  # pollutants only\n",
    "        if len(sub) < 2:\n",
    "            corr_dict[col] = np.nan  # Not enough data\n",
    "        else:\n",
    "            r, _ = pearsonr(sub['wind_speed'], sub[col])\n",
    "            corr_dict[col] = r\n",
    "    return pd.Series(corr_dict, name='wind_speed')\n",
    "\n",
    "# --- Print subset sizes for info ---\n",
    "print(\"All days:\", len(df))\n",
    "print(\"NFD:\", len(get_subset(0)))\n",
    "for i in range(1,6):\n",
    "    print(f\"Day{i}:\", len(get_subset(i)))\n",
    "\n",
    "# --- Build full correlation table ---\n",
    "all_days = compute_corr(df.index)\n",
    "nfd = compute_corr(get_subset(0))\n",
    "day_tables = [compute_corr(get_subset(i)) for i in range(1,6)]\n",
    "\n",
    "day_tables = [compute_corr(get_subset(i)) for i in range(1,7)]  # 1 to 6 inclusive\n",
    "full_table = pd.concat([all_days, nfd] + day_tables, axis=1)\n",
    "full_table.columns = ['All_days', 'NFD', 'Day0','Day1','Day2','Day3','Day4','Day5']\n",
    "\n",
    "print(full_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53094490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load wind dataset (hourly, 0.25° grid)\n",
    "# -------------------------\n",
    "wind_folder = r\"D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\"\n",
    "wind_files = sorted(glob.glob(os.path.join(wind_folder, \"*.nc\")))\n",
    "\n",
    "ds_wind = xr.open_mfdataset(wind_files, combine=\"by_coords\")\n",
    "\n",
    "# Detect correct time coordinate\n",
    "time_coord = None\n",
    "for cand in [\"time\", \"valid_time\", \"date\", \"time_counter\"]:\n",
    "    if cand in ds_wind.dims or cand in ds_wind.coords:\n",
    "        time_coord = cand\n",
    "        break\n",
    "if time_coord is None:\n",
    "    raise ValueError(\"❌ Could not find a time coordinate in wind dataset\")\n",
    "\n",
    "# Regrid 0.25° → 0.75° (3x3 bins)\n",
    "wind_coarse = ds_wind.coarsen(latitude=3, longitude=3, boundary=\"trim\").mean()\n",
    "\n",
    "# Hourly → daily mean\n",
    "wind_daily = wind_coarse[\"wind_speed\"].resample({time_coord: \"1D\"}).mean()\n",
    "\n",
    "# Regional average (Portugal)\n",
    "wind_series = wind_daily.mean(dim=[\"latitude\", \"longitude\"]).to_pandas()\n",
    "wind_series.name = \"wind_speed\"\n",
    "\n",
    "# -------------------------\n",
    "# 2. Load pollutant datasets (already daily + fire labels)\n",
    "# -------------------------\n",
    "pollutants_files = {\n",
    "    \"CO\":   r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\":r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\":  r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\":   r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\",\n",
    "}\n",
    "\n",
    "pollutants = {}\n",
    "fire_labels = None\n",
    "\n",
    "for pol, path in pollutants_files.items():\n",
    "    ds = xr.open_dataset(path)\n",
    "\n",
    "    # ✅ Take spatial mean over lat/lon to get a single daily series\n",
    "    pol_series = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"]).to_pandas()\n",
    "    pol_series.name = pol\n",
    "    pollutants[pol] = pol_series\n",
    "\n",
    "    # ✅ Fire labels: take spatial mean and round (they should already be consistent across grid)\n",
    "    if fire_labels is None:\n",
    "        label_var = [v for v in ds.data_vars if \"fire_label\" in v][0]\n",
    "        fire_labels = ds[label_var].mean(dim=[\"latitude\", \"longitude\"]).round().astype(int).to_pandas()\n",
    "\n",
    "# -------------------------\n",
    "# 3. Combine into one dataframe\n",
    "# -------------------------\n",
    "df = pd.concat(pollutants.values(), axis=1)\n",
    "df[\"wind_speed\"] = wind_series\n",
    "df[\"fire_label\"] = fire_labels\n",
    "df = df.dropna()\n",
    "\n",
    "# -------------------------\n",
    "# 4. Correlation helper\n",
    "# -------------------------\n",
    "def compute_corr(subset):\n",
    "    \"\"\"Return correlation between wind_speed and all pollutants.\"\"\"\n",
    "    return subset.corr().loc[\"wind_speed\", [\"CO\", \"NO\", \"NO2\", \"PM2.5\", \"PM10\"]]\n",
    "\n",
    "# All data (no filtering)\n",
    "all_days = compute_corr(df)\n",
    "\n",
    "# Label-based subsets\n",
    "corrs_by_label = {}\n",
    "for label in range(6):  # 0 = NFD, 1=Day0 ... 5=Day5\n",
    "    subset = df[df[\"fire_label\"] == label]\n",
    "    if not subset.empty:\n",
    "        corrs_by_label[label] = compute_corr(subset)\n",
    "    else:\n",
    "        corrs_by_label[label] = pd.Series([np.nan]*5, index=[\"CO\",\"NO\",\"NO2\",\"PM2.5\",\"PM10\"])\n",
    "\n",
    "# -------------------------\n",
    "# 5. Build final correlation table\n",
    "# -------------------------\n",
    "# Build final correlation table\n",
    "corr_table = pd.concat(\n",
    "    [all_days,\n",
    "     corrs_by_label[0],  # NFD\n",
    "     corrs_by_label[1],  # Day0\n",
    "     corrs_by_label[2],  # Day1\n",
    "     corrs_by_label[3],  # Day2\n",
    "     corrs_by_label[4],  # Day3\n",
    "     corrs_by_label[5],  # Day4\n",
    "     corrs_by_label[6]], # Day5\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "corr_table.columns = [\"All_days\", \"NFD\", \"Day0\", \"Day1\", \"Day2\", \"Day3\", \"Day4\", \"Day5\"]\n",
    "\n",
    "print(corr_table)\n",
    "\n",
    "# Save to Excel\n",
    "corr_table.to_excel(r\"D:\\IPMA\\Results\\wind_pollutant_correlation_Portugal.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ad764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20239a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
