{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5837e9",
   "metadata": {},
   "source": [
    "mean +- standard error of mean of pollutants on day without fire, with fire and up to 5 days after fire outbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52216297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Portugal'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000    \n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Portugal):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec16065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Italy'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Italy):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5400942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Spain'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Spain):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff276096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Greece'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Greece):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e2468",
   "metadata": {},
   "source": [
    "Divide daily concentrations of pollutants into quartiles Q1 (lowest), Q2, Q3 and Q4 (highest) for days when fires occurred and days they did not - Assess the impact of fire events on the concentration of air pollutants. Calculation of percentage of days (non-wildfire and wildfire) in each of the four qaurtiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b929c10",
   "metadata": {},
   "source": [
    "Splits pollutant concentrations into quartiles (25% intervals) separately for fire and no-fire cases:\n",
    "\n",
    "Q1 = lowest 25%\n",
    "\n",
    "Q2 = 25–50%\n",
    "\n",
    "Q3 = 50–75%\n",
    "\n",
    "Q4 = highest 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfaa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- List of pollutant files ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "all_ranges = []   # <-- NEW\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if needed\n",
    "    fire_flag = ds[\"fire_binary_Portugal\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Drop NaNs before analysis\n",
    "    df = df.dropna(subset=[\"pollutant\", \"fire\"])\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # --- Counts ---\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # --- Percentages ---\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "    # --- Quartile ranges (NEW) ---\n",
    "    for fire_status, subset in [(\"fire\", df_fire), (\"no-fire\", df_nofire)]:\n",
    "        if len(subset) > 0:\n",
    "            edges = np.percentile(subset[\"pollutant\"], [0, 25, 50, 75, 100])\n",
    "            all_ranges.append({\n",
    "                \"pollutant\": pol_name,\n",
    "                \"fire_status\": fire_status,\n",
    "                \"min\": edges[0],\n",
    "                \"Q1_cut\": edges[1],\n",
    "                \"median\": edges[2],\n",
    "                \"Q3_cut\": edges[3],\n",
    "                \"max\": edges[4]\n",
    "            })\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "ranges_table = pd.DataFrame(all_ranges)\n",
    "\n",
    "print(\"\\nQuartile ranges table:\")\n",
    "print(ranges_table)\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- List of pollutant files ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "all_ranges = []   # <-- NEW\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if needed\n",
    "    fire_flag = ds[\"fire_binary_Italy\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Drop NaNs before analysis\n",
    "    df = df.dropna(subset=[\"pollutant\", \"fire\"])\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # --- Counts ---\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # --- Percentages ---\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "    # --- Quartile ranges (NEW) ---\n",
    "    for fire_status, subset in [(\"fire\", df_fire), (\"no-fire\", df_nofire)]:\n",
    "        if len(subset) > 0:\n",
    "            edges = np.percentile(subset[\"pollutant\"], [0, 25, 50, 75, 100])\n",
    "            all_ranges.append({\n",
    "                \"pollutant\": pol_name,\n",
    "                \"fire_status\": fire_status,\n",
    "                \"min\": edges[0],\n",
    "                \"Q1_cut\": edges[1],\n",
    "                \"median\": edges[2],\n",
    "                \"Q3_cut\": edges[3],\n",
    "                \"max\": edges[4]\n",
    "            })\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "ranges_table = pd.DataFrame(all_ranges)\n",
    "\n",
    "print(\"\\nQuartile ranges table:\")\n",
    "print(ranges_table)\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91da6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- List of pollutant files ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "all_ranges = []   # <-- NEW\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if needed\n",
    "    fire_flag = ds[\"fire_binary_Spain\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Drop NaNs before analysis\n",
    "    df = df.dropna(subset=[\"pollutant\", \"fire\"])\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # --- Counts ---\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # --- Percentages ---\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "    # --- Quartile ranges (NEW) ---\n",
    "    for fire_status, subset in [(\"fire\", df_fire), (\"no-fire\", df_nofire)]:\n",
    "        if len(subset) > 0:\n",
    "            edges = np.percentile(subset[\"pollutant\"], [0, 25, 50, 75, 100])\n",
    "            all_ranges.append({\n",
    "                \"pollutant\": pol_name,\n",
    "                \"fire_status\": fire_status,\n",
    "                \"min\": edges[0],\n",
    "                \"Q1_cut\": edges[1],\n",
    "                \"median\": edges[2],\n",
    "                \"Q3_cut\": edges[3],\n",
    "                \"max\": edges[4]\n",
    "            })\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "ranges_table = pd.DataFrame(all_ranges)\n",
    "\n",
    "print(\"\\nQuartile ranges table:\")\n",
    "print(ranges_table)\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc95045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- List of pollutant files ---\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "all_ranges = []   # <-- NEW\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    pollutant = ds[\"Mean\"]  # adjust if needed\n",
    "    fire_flag = ds[\"fire_binary_Greece\"]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pollutant.to_dataframe(name=\"pollutant\").reset_index()\n",
    "    df[\"fire\"] = fire_flag.to_dataframe(name=\"fire\").reset_index(drop=True)\n",
    "\n",
    "    # Drop NaNs before analysis\n",
    "    df = df.dropna(subset=[\"pollutant\", \"fire\"])\n",
    "\n",
    "    # Split into fire / no-fire\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "\n",
    "    # Quartiles within each group\n",
    "    df_fire[\"quartile\"] = pd.qcut(df_fire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "    df_nofire[\"quartile\"] = pd.qcut(df_nofire[\"pollutant\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
    "\n",
    "    df_quartiles = pd.concat([df_fire, df_nofire])\n",
    "\n",
    "    # --- Counts ---\n",
    "    summary_counts = df_quartiles.groupby([\"fire\", \"quartile\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # --- Percentages ---\n",
    "    summary_pct = summary_counts.div(summary_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Add pollutant name for identification\n",
    "    summary_counts[\"pollutant\"] = pol_name\n",
    "    summary_pct[\"pollutant\"] = pol_name\n",
    "\n",
    "    all_results.append((summary_counts, summary_pct))\n",
    "\n",
    "    # --- Quartile ranges (NEW) ---\n",
    "    for fire_status, subset in [(\"fire\", df_fire), (\"no-fire\", df_nofire)]:\n",
    "        if len(subset) > 0:\n",
    "            edges = np.percentile(subset[\"pollutant\"], [0, 25, 50, 75, 100])\n",
    "            all_ranges.append({\n",
    "                \"pollutant\": pol_name,\n",
    "                \"fire_status\": fire_status,\n",
    "                \"min\": edges[0],\n",
    "                \"Q1_cut\": edges[1],\n",
    "                \"median\": edges[2],\n",
    "                \"Q3_cut\": edges[3],\n",
    "                \"max\": edges[4]\n",
    "            })\n",
    "\n",
    "# --- Combine all pollutants ---\n",
    "counts_table = pd.concat([c for c, p in all_results], axis=0).reset_index()\n",
    "percentages_table = pd.concat([p for c, p in all_results], axis=0).reset_index()\n",
    "ranges_table = pd.DataFrame(all_ranges)\n",
    "\n",
    "print(\"\\nQuartile ranges table:\")\n",
    "print(ranges_table)\n",
    "\n",
    "print(\"Counts table:\")\n",
    "print(counts_table)\n",
    "\n",
    "print(\"\\nPercentages table:\")\n",
    "print(percentages_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fd26f",
   "metadata": {},
   "source": [
    "Pearson correlation performed between meteorological variables and air pollutants, for all days and every label established"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37287cd9",
   "metadata": {},
   "source": [
    "Wind speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ad764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None  # store the first dataset for fire labels\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    \n",
    "    # Daily spatial mean (skip NaNs)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    \n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset with fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Wind dataset (corrected multi-year loading)\n",
    "# --------------------\n",
    "wind_files = glob.glob(r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_yearly_regridded\\daily_wind_speed_stats_*_regrid.nc\")\n",
    "datasets = [xr.open_dataset(f) for f in wind_files]\n",
    "ds_wind = xr.concat(datasets, dim=\"Year\")\n",
    "\n",
    "# Build datetime index\n",
    "years = ds_wind[\"Year\"].values\n",
    "months = ds_wind[\"Month\"].values\n",
    "days = ds_wind[\"Day\"].values\n",
    "\n",
    "time_list = []\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        for d in days:\n",
    "            try:\n",
    "                time_list.append(pd.Timestamp(year=int(y), month=int(m), day=int(d)))\n",
    "            except ValueError:\n",
    "                continue  # skip invalid dates\n",
    "\n",
    "time_index = pd.DatetimeIndex(time_list)\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_wind = ds_wind.stack(date=(\"Year\",\"Month\",\"Day\"))\n",
    "ds_wind = ds_wind.assign_coords(time=(\"date\", time_index))\n",
    "ds_wind = ds_wind.swap_dims({\"date\":\"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean wind speed\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\",\"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"WindSpeed\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0, 7):\n",
    "    mask = fire_ds[\"fire_label_Portugal\"] == label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation functions\n",
    "# --------------------\n",
    "def correlation(df, pollutants, label_name=\"All\", mask=None):\n",
    "    results = []\n",
    "    if mask is not None:\n",
    "        df = df[mask]\n",
    "    if len(df) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"WindSpeed\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + wind)\n",
    "# --------------------\n",
    "df_all = pd.concat(\n",
    "    list(pollutant_series.values()) + [wind_ts],\n",
    "    axis=1,\n",
    "    keys=list(pollutant_series.keys()) + [\"WindSpeed\"]\n",
    ")\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation(df_all, pollutant_names, label_name=label, mask=mask_aligned))\n",
    "\n",
    "# --------------------\n",
    "# 6. Save results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(\n",
    "    r\"D:\\IPMA\\CAMS\\pollutant_wind_correlations_by_fire_label_Portugal.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21238a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None  # store the first dataset for fire labels\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    \n",
    "    # Daily spatial mean (skip NaNs)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    \n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset with fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Wind dataset\n",
    "# --------------------\n",
    "wind_file = r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_regrid.nc\"\n",
    "ds_wind = xr.open_dataset(wind_file)\n",
    "\n",
    "# Build datetime index\n",
    "years = ds_wind[\"Year\"].values\n",
    "months = ds_wind[\"Month\"].values\n",
    "days = ds_wind[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    [f\"{y}-{m:02d}-{d:02d}\" for y in years for m in months for d in days],\n",
    "    errors=\"coerce\"\n",
    ").dropna()\n",
    "\n",
    "# Stack Year, Month, Day into a single dimension\n",
    "ds_wind = ds_wind.stack(date=(\"Year\",\"Month\",\"Day\"))\n",
    "ds_wind = ds_wind.assign_coords(time=(\"date\", time_index))\n",
    "ds_wind = ds_wind.swap_dims({\"date\":\"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean wind speed\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\",\"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"WindSpeed\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Italy\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"WindSpeed\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"WindSpeed\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + wind)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_wind_correlations_by_fire_label_Italy.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20239a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None  # store the first dataset for fire labels\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    \n",
    "    # Daily spatial mean (skip NaNs)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    \n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset with fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Wind dataset\n",
    "# --------------------\n",
    "wind_file = r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_regrid.nc\"\n",
    "ds_wind = xr.open_dataset(wind_file)\n",
    "\n",
    "# Build datetime index\n",
    "years = ds_wind[\"Year\"].values\n",
    "months = ds_wind[\"Month\"].values\n",
    "days = ds_wind[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    [f\"{y}-{m:02d}-{d:02d}\" for y in years for m in months for d in days],\n",
    "    errors=\"coerce\"\n",
    ").dropna()\n",
    "\n",
    "# Stack Year, Month, Day into a single dimension\n",
    "ds_wind = ds_wind.stack(date=(\"Year\",\"Month\",\"Day\"))\n",
    "ds_wind = ds_wind.assign_coords(time=(\"date\", time_index))\n",
    "ds_wind = ds_wind.swap_dims({\"date\":\"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean wind speed\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\",\"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"WindSpeed\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Spain\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"WindSpeed\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"WindSpeed\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + wind)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_wind_correlations_by_fire_label_Spain.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318451be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None  # store the first dataset for fire labels\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    \n",
    "    # Daily spatial mean (skip NaNs)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    \n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset with fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Wind dataset\n",
    "# --------------------\n",
    "wind_file = r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_regrid.nc\"\n",
    "ds_wind = xr.open_dataset(wind_file)\n",
    "\n",
    "# Build datetime index\n",
    "years = ds_wind[\"Year\"].values\n",
    "months = ds_wind[\"Month\"].values\n",
    "days = ds_wind[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    [f\"{y}-{m:02d}-{d:02d}\" for y in years for m in months for d in days],\n",
    "    errors=\"coerce\"\n",
    ").dropna()\n",
    "\n",
    "# Stack Year, Month, Day into a single dimension\n",
    "ds_wind = ds_wind.stack(date=(\"Year\",\"Month\",\"Day\"))\n",
    "ds_wind = ds_wind.assign_coords(time=(\"date\", time_index))\n",
    "ds_wind = ds_wind.swap_dims({\"date\":\"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean wind speed\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\",\"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"WindSpeed\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Greece\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"WindSpeed\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"WindSpeed\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + wind)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_wind_correlations_by_fire_label_Greece.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227e7f0",
   "metadata": {},
   "source": [
    "Total Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f28577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation results saved to CSV.\n",
      "FireLabel Pollutant  Pearson_r    Pearson_p  Spearman_r   Spearman_p\n",
      "      All        CO  -0.080466 5.598159e-13   -0.122477 3.913681e-28\n",
      "      All     PM2.5  -0.128727 6.301294e-31   -0.213593 2.957227e-83\n",
      "      All      PM10  -0.108419 2.302336e-22   -0.166530 7.116551e-51\n",
      "      All       NO2  -0.123881 9.492308e-29   -0.125814 1.315172e-29\n",
      "      All        NO  -0.051974 3.278822e-06   -0.154166 9.079908e-44\n",
      "        0        CO  -0.080466 5.598159e-13   -0.122477 3.913681e-28\n",
      "        0     PM2.5  -0.128727 6.301294e-31   -0.213593 2.957227e-83\n",
      "        0      PM10  -0.108419 2.302336e-22   -0.166530 7.116551e-51\n",
      "        0       NO2  -0.123881 9.492308e-29   -0.125814 1.315172e-29\n",
      "        0        NO  -0.051974 3.278822e-06   -0.154166 9.079908e-44\n",
      "        1        CO  -0.056788 2.683047e-02   -0.141001 3.383884e-08\n",
      "        1     PM2.5  -0.088396 5.601037e-04   -0.204364 8.549511e-16\n",
      "        1      PM10  -0.084189 1.018225e-03   -0.190662 6.574106e-14\n",
      "        1       NO2  -0.086763 7.085694e-04   -0.105679 3.654659e-05\n",
      "        1        NO  -0.039429 1.243992e-01   -0.102203 6.557479e-05\n",
      "        2        CO  -0.082270 7.446617e-02   -0.150477 1.053895e-03\n",
      "        2     PM2.5  -0.095271 3.875103e-02   -0.154259 7.821453e-04\n",
      "        2      PM10  -0.093145 4.333069e-02   -0.149672 1.122012e-03\n",
      "        2       NO2  -0.090168 5.050584e-02   -0.137656 2.755130e-03\n",
      "        2        NO  -0.071348 1.220353e-01   -0.150898 1.019829e-03\n",
      "        3        CO  -0.095389 1.423234e-01   -0.067258 3.014600e-01\n",
      "        3     PM2.5  -0.039827 5.409142e-01   -0.091767 1.581757e-01\n",
      "        3      PM10  -0.036167 5.787620e-01   -0.090312 1.649017e-01\n",
      "        3       NO2  -0.063068 3.326376e-01   -0.007255 9.113482e-01\n",
      "        3        NO  -0.099977 1.240232e-01   -0.079283 2.229945e-01\n",
      "        4        CO  -0.084809 3.244567e-01   -0.048976 5.698050e-01\n",
      "        4     PM2.5  -0.040645 6.372347e-01   -0.035838 6.775808e-01\n",
      "        4      PM10  -0.035380 6.814810e-01   -0.031722 7.128833e-01\n",
      "        4       NO2  -0.069884 4.170962e-01   -0.007589 9.298687e-01\n",
      "        4        NO  -0.095749 2.657053e-01   -0.049718 5.639661e-01\n",
      "        5        CO  -0.098292 3.459314e-01    0.001207 9.907917e-01\n",
      "        5     PM2.5  -0.079948 4.436855e-01    0.003157 9.759072e-01\n",
      "        5      PM10  -0.075664 4.685643e-01    0.002651 9.797656e-01\n",
      "        5       NO2  -0.086338 4.079986e-01    0.023733 8.203825e-01\n",
      "        5        NO  -0.120393 2.477440e-01    0.001828 9.860502e-01\n",
      "        6        CO  -0.147342 2.654359e-01   -0.058504 6.598367e-01\n",
      "        6     PM2.5  -0.107037 4.197263e-01   -0.102805 4.384439e-01\n",
      "        6      PM10  -0.104422 4.312369e-01   -0.104267 4.319284e-01\n",
      "        6       NO2  -0.097830 4.610388e-01   -0.054880 6.797277e-01\n",
      "        6        NO  -0.241057 6.588573e-02   -0.181181 1.696609e-01\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Precipitation dataset (multiple yearly files)\n",
    "# --------------------\n",
    "precip_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_yearly_regridded\\daily_precipitation_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in precip_files]\n",
    "ds_precip = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_precip = ds_precip.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_precip = ds_precip.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_precip = ds_precip.assign_coords(time=(\"date\", time_index))\n",
    "ds_precip = ds_precip.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean of total precipitation\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0, 7):\n",
    "    mask = fire_ds[\"fire_label_Portugal\"] == label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\", \"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation functions\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Precipitation\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Precipitation\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Save results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_precipitation_correlations_by_fire_label_Portugal.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f48b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No invalid dates found.\n",
      "\n",
      "Number of days per fire label:\n",
      "Fire Label 0: Before drop NaN = 8036, After drop NaN = 8005\n",
      "Fire Label 1: Before drop NaN = 1520, After drop NaN = 1520\n",
      "Fire Label 2: Before drop NaN = 471, After drop NaN = 471\n",
      "Fire Label 3: Before drop NaN = 238, After drop NaN = 238\n",
      "Fire Label 4: Before drop NaN = 137, After drop NaN = 137\n",
      "Fire Label 5: Before drop NaN = 94, After drop NaN = 94\n",
      "Fire Label 6: Before drop NaN = 59, After drop NaN = 59\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + precipitation)\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b358bd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation results saved to CSV.\n",
      "FireLabel Pollutant  Pearson_r    Pearson_p  Spearman_r   Spearman_p\n",
      "      All        CO   0.002178 8.455022e-01    0.013340 2.327232e-01\n",
      "      All     PM2.5  -0.122759 2.948227e-28   -0.145867 2.563738e-39\n",
      "      All      PM10  -0.105296 3.531798e-21   -0.120618 2.489953e-27\n",
      "      All       NO2   0.058834 1.381854e-07    0.071907 1.187644e-10\n",
      "      All        NO   0.099689 3.886345e-19    0.100217 2.523323e-19\n",
      "        0        CO   0.002178 8.455022e-01    0.013340 2.327232e-01\n",
      "        0     PM2.5  -0.122759 2.948227e-28   -0.145867 2.563738e-39\n",
      "        0      PM10  -0.105296 3.531798e-21   -0.120618 2.489953e-27\n",
      "        0       NO2   0.058834 1.381854e-07    0.071907 1.187644e-10\n",
      "        0        NO   0.099689 3.886345e-19    0.100217 2.523323e-19\n",
      "        1        CO  -0.128928 7.839295e-09   -0.161975 3.618210e-13\n",
      "        1     PM2.5  -0.127873 1.038728e-08   -0.136565 9.539817e-10\n",
      "        1      PM10  -0.115236 2.542326e-07   -0.116911 1.695159e-07\n",
      "        1       NO2  -0.118130 1.257792e-07   -0.124204 2.717416e-08\n",
      "        1        NO  -0.016353 4.659540e-01   -0.115144 2.599102e-07\n",
      "        2        CO  -0.215336 4.037559e-06   -0.213367 4.963967e-06\n",
      "        2     PM2.5  -0.097938 3.782138e-02   -0.097147 3.940407e-02\n",
      "        2      PM10  -0.088642 6.026398e-02   -0.084748 7.249202e-02\n",
      "        2       NO2  -0.246034 1.249320e-07   -0.232906 5.859076e-07\n",
      "        2        NO  -0.198813 2.154900e-05   -0.277415 2.145437e-09\n",
      "        3        CO  -0.171301 2.780960e-02   -0.147236 5.913259e-02\n",
      "        3     PM2.5  -0.116683 1.355594e-01   -0.094895 2.253524e-01\n",
      "        3      PM10  -0.103910 1.841113e-01   -0.079550 3.097807e-01\n",
      "        3       NO2  -0.234239 2.459950e-03   -0.207371 7.526871e-03\n",
      "        3        NO  -0.138226 7.663387e-02   -0.249261 1.244002e-03\n",
      "        4        CO  -0.123660 3.382799e-01   -0.113848 3.782840e-01\n",
      "        4     PM2.5  -0.087309 4.998212e-01   -0.097227 4.521873e-01\n",
      "        4      PM10  -0.072448 5.757618e-01   -0.077032 5.517843e-01\n",
      "        4       NO2  -0.174433 1.751120e-01   -0.174838 1.740973e-01\n",
      "        4        NO  -0.281827 2.647712e-02   -0.229181 7.316851e-02\n",
      "        5        CO  -0.330808 1.062654e-01   -0.330769 1.063085e-01\n",
      "        5     PM2.5  -0.157557 4.519496e-01   -0.194615 3.512254e-01\n",
      "        5      PM10  -0.145349 4.881632e-01   -0.153846 4.628040e-01\n",
      "        5       NO2  -0.146878 4.835478e-01   -0.142308 4.974061e-01\n",
      "        5        NO  -0.246806 2.342973e-01   -0.080000 7.038476e-01\n",
      "        6        CO  -0.026583 9.381604e-01   -0.081818 8.109904e-01\n",
      "        6     PM2.5  -0.032199 9.251249e-01   -0.154545 6.500340e-01\n",
      "        6      PM10  -0.013995 9.674241e-01   -0.072727 8.317164e-01\n",
      "        6       NO2  -0.181102 5.940973e-01   -0.200000 5.554454e-01\n",
      "        6        NO  -0.369467 2.634445e-01   -0.345455 2.980892e-01\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# 2. Precipitation dataset (multiple yearly files)\n",
    "# --------------------\n",
    "precip_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_yearly_regridded\\daily_precipitation_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in precip_files]\n",
    "ds_precip = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_precip = ds_precip.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_precip = ds_precip.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_precip = ds_precip.assign_coords(time=(\"date\", time_index))\n",
    "ds_precip = ds_precip.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean of total precipitation\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Italy\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\", \"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Precipitation\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Precipitation\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + precipitation)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_precipitation_correlations_by_fire_label_Italy.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b219f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No invalid dates found.\n",
      "\n",
      "Number of days per fire label:\n",
      "Fire Label 0: Before drop NaN = 8036, After drop NaN = 8005\n",
      "Fire Label 1: Before drop NaN = 1990, After drop NaN = 1990\n",
      "Fire Label 2: Before drop NaN = 450, After drop NaN = 450\n",
      "Fire Label 3: Before drop NaN = 165, After drop NaN = 165\n",
      "Fire Label 4: Before drop NaN = 62, After drop NaN = 62\n",
      "Fire Label 5: Before drop NaN = 25, After drop NaN = 25\n",
      "Fire Label 6: Before drop NaN = 11, After drop NaN = 11\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + precipitation)\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9969e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation results saved to CSV.\n",
      "FireLabel Pollutant  Pearson_r     Pearson_p  Spearman_r    Spearman_p\n",
      "      All        CO  -0.096539  4.874706e-18   -0.074079  3.224354e-11\n",
      "      All     PM2.5  -0.316072 3.482753e-185   -0.372187 1.802676e-261\n",
      "      All      PM10  -0.293053 2.735504e-158   -0.331956 3.407424e-205\n",
      "      All       NO2  -0.007655  4.934977e-01   -0.014001  2.103857e-01\n",
      "      All        NO  -0.002853  7.985872e-01   -0.046701  2.914665e-05\n",
      "        0        CO  -0.096539  4.874706e-18   -0.074079  3.224354e-11\n",
      "        0     PM2.5  -0.316072 3.482753e-185   -0.372187 1.802676e-261\n",
      "        0      PM10  -0.293053 2.735504e-158   -0.331956 3.407424e-205\n",
      "        0       NO2  -0.007655  4.934977e-01   -0.014001  2.103857e-01\n",
      "        0        NO  -0.002853  7.985872e-01   -0.046701  2.914665e-05\n",
      "        1        CO  -0.105420  2.512263e-07   -0.116667  1.126186e-08\n",
      "        1     PM2.5  -0.278283  1.287661e-43   -0.322564  8.366587e-59\n",
      "        1      PM10  -0.262461  8.048397e-39   -0.297248  8.523708e-50\n",
      "        1       NO2  -0.016999  4.069615e-01   -0.055998  6.261737e-03\n",
      "        1        NO   0.023597  2.496483e-01   -0.060888  2.950215e-03\n",
      "        2        CO  -0.133173  3.050248e-03   -0.168497  1.708275e-04\n",
      "        2     PM2.5  -0.226740  3.616940e-07   -0.292989  3.244058e-11\n",
      "        2      PM10  -0.216506  1.218077e-06   -0.273921  6.199016e-10\n",
      "        2       NO2  -0.068194  1.305174e-01   -0.104212  2.065008e-02\n",
      "        2        NO  -0.029359  5.154644e-01   -0.085662  5.734563e-02\n",
      "        3        CO  -0.192533  9.614957e-03   -0.283431  1.154968e-04\n",
      "        3     PM2.5  -0.213664  3.977222e-03   -0.281097  1.321582e-04\n",
      "        3      PM10  -0.203816  6.064142e-03   -0.273099  2.078796e-04\n",
      "        3       NO2  -0.122144  1.023776e-01   -0.158386  3.370494e-02\n",
      "        3        NO  -0.023763  7.515184e-01   -0.155087  3.763477e-02\n",
      "        4        CO  -0.239456  2.729945e-02   -0.303166  4.796884e-03\n",
      "        4     PM2.5  -0.235526  3.001290e-02   -0.295173  6.098152e-03\n",
      "        4      PM10  -0.226947  3.673423e-02   -0.287512  7.628842e-03\n",
      "        4       NO2  -0.225817  3.770682e-02   -0.251671  2.015402e-02\n",
      "        4        NO  -0.190156  8.130932e-02   -0.280887  9.215417e-03\n",
      "        5        CO  -0.334371  3.261935e-02   -0.346516  2.645732e-02\n",
      "        5     PM2.5  -0.332576  3.362344e-02   -0.290767  6.513790e-02\n",
      "        5      PM10  -0.323586  3.903881e-02   -0.275784  8.093389e-02\n",
      "        5       NO2  -0.237664  1.345859e-01   -0.347561  2.597550e-02\n",
      "        5        NO  -0.291913  6.403834e-02   -0.282056  7.399272e-02\n",
      "        6        CO  -0.020366  9.381600e-01   -0.316176  2.163270e-01\n",
      "        6     PM2.5  -0.122894  6.384288e-01   -0.254902  3.234600e-01\n",
      "        6      PM10  -0.118591  6.503159e-01   -0.252451  3.282942e-01\n",
      "        6       NO2   0.049286  8.509979e-01    0.034314  8.959808e-01\n",
      "        6        NO   0.115364  6.592825e-01   -0.073529  7.791273e-01\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Precipitation dataset (multiple yearly files)\n",
    "# --------------------\n",
    "precip_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_yearly_regridded\\daily_precipitation_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in precip_files]\n",
    "ds_precip = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_precip = ds_precip.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_precip = ds_precip.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_precip = ds_precip.assign_coords(time=(\"date\", time_index))\n",
    "ds_precip = ds_precip.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean of total precipitation\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Spain\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Precipitation\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Precipitation\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + precipitation)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_precipitation_correlations_by_fire_label_Spain.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6243135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No invalid dates found.\n",
      "\n",
      "Number of days per fire label:\n",
      "Fire Label 0: Before drop NaN = 8036, After drop NaN = 8005\n",
      "Fire Label 1: Before drop NaN = 2384, After drop NaN = 2382\n",
      "Fire Label 2: Before drop NaN = 493, After drop NaN = 493\n",
      "Fire Label 3: Before drop NaN = 180, After drop NaN = 180\n",
      "Fire Label 4: Before drop NaN = 85, After drop NaN = 85\n",
      "Fire Label 5: Before drop NaN = 41, After drop NaN = 41\n",
      "Fire Label 6: Before drop NaN = 17, After drop NaN = 17\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + precipitation)\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79ec7ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation results saved to CSV.\n",
      "FireLabel Pollutant  Pearson_r    Pearson_p  Spearman_r   Spearman_p\n",
      "      All        CO  -0.046102 3.686414e-05   -0.034874 1.804434e-03\n",
      "      All     PM2.5   0.008725 4.351080e-01   -0.072716 7.337158e-11\n",
      "      All      PM10   0.012042 2.813469e-01   -0.065907 3.585211e-09\n",
      "      All       NO2   0.147757 2.616319e-40    0.180305 1.807327e-59\n",
      "      All        NO   0.093468 5.307814e-17    0.159656 7.474738e-47\n",
      "        0        CO  -0.046102 3.686414e-05   -0.034874 1.804434e-03\n",
      "        0     PM2.5   0.008725 4.351080e-01   -0.072716 7.337158e-11\n",
      "        0      PM10   0.012042 2.813469e-01   -0.065907 3.585211e-09\n",
      "        0       NO2   0.147757 2.616319e-40    0.180305 1.807327e-59\n",
      "        0        NO   0.093468 5.307814e-17    0.159656 7.474738e-47\n",
      "        1        CO  -0.030378 1.814088e-01   -0.031897 1.605378e-01\n",
      "        1     PM2.5  -0.001266 9.556030e-01   -0.049859 2.821161e-02\n",
      "        1      PM10  -0.002738 9.041320e-01   -0.050827 2.528841e-02\n",
      "        1       NO2   0.095027 2.801494e-05    0.135058 2.407298e-09\n",
      "        1        NO   0.058428 1.011035e-02    0.158090 2.608944e-12\n",
      "        2        CO  -0.004744 9.266620e-01   -0.005531 9.145371e-01\n",
      "        2     PM2.5   0.068413 1.838404e-01    0.047439 3.570428e-01\n",
      "        2      PM10   0.065380 2.040951e-01    0.041926 4.157215e-01\n",
      "        2       NO2   0.034311 5.054435e-01    0.068004 1.864850e-01\n",
      "        2        NO  -0.019082 7.111602e-01    0.036077 4.837671e-01\n",
      "        3        CO   0.000965 9.914127e-01   -0.018244 8.386806e-01\n",
      "        3     PM2.5   0.071464 4.246289e-01   -0.001969 9.824762e-01\n",
      "        3      PM10   0.068469 4.443428e-01   -0.002619 9.766885e-01\n",
      "        3       NO2   0.010692 9.050319e-01   -0.020423 8.197192e-01\n",
      "        3        NO  -0.049356 5.815982e-01    0.015525 8.624605e-01\n",
      "        4        CO  -0.073156 5.886429e-01   -0.023982 8.594479e-01\n",
      "        4     PM2.5  -0.001551 9.908618e-01   -0.067410 6.183249e-01\n",
      "        4      PM10  -0.006096 9.641063e-01   -0.081346 5.474818e-01\n",
      "        4       NO2   0.024197 8.582058e-01    0.127690 3.438620e-01\n",
      "        4        NO  -0.117495 3.840634e-01    0.073503 5.868717e-01\n",
      "        5        CO   0.134944 4.935690e-01    0.107827 5.849627e-01\n",
      "        5     PM2.5   0.268158 1.676828e-01    0.268747 1.667161e-01\n",
      "        5      PM10   0.264273 1.741617e-01    0.261631 1.786682e-01\n",
      "        5       NO2   0.223446 2.530460e-01    0.265463 1.721601e-01\n",
      "        5        NO  -0.029819 8.802691e-01    0.154351 4.329050e-01\n",
      "        6        CO   0.175455 4.468160e-01   -0.072727 7.540637e-01\n",
      "        6     PM2.5   0.212829 3.543110e-01   -0.066234 7.754535e-01\n",
      "        6      PM10   0.206529 3.690689e-01   -0.087013 7.076308e-01\n",
      "        6       NO2   0.217040 3.446428e-01   -0.066234 7.754535e-01\n",
      "        6        NO   0.063414 7.847917e-01   -0.175325 4.471597e-01\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Precipitation dataset (multiple yearly files)\n",
    "# --------------------\n",
    "precip_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_yearly_regridded\\daily_precipitation_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in precip_files]\n",
    "ds_precip = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_precip = ds_precip.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_precip = ds_precip.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_precip = ds_precip.assign_coords(time=(\"date\", time_index))\n",
    "ds_precip = ds_precip.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean of total precipitation\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Greece\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Precipitation\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Precipitation\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + precipitation)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_precipitation_correlations_by_fire_label_Greece.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03a41bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No invalid dates found.\n",
      "\n",
      "Number of days per fire label:\n",
      "Fire Label 0: Before drop NaN = 8036, After drop NaN = 8005\n",
      "Fire Label 1: Before drop NaN = 1937, After drop NaN = 1937\n",
      "Fire Label 2: Before drop NaN = 379, After drop NaN = 379\n",
      "Fire Label 3: Before drop NaN = 127, After drop NaN = 127\n",
      "Fire Label 4: Before drop NaN = 57, After drop NaN = 57\n",
      "Fire Label 5: Before drop NaN = 28, After drop NaN = 28\n",
      "Fire Label 6: Before drop NaN = 21, After drop NaN = 21\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + precipitation)\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce8d9a",
   "metadata": {},
   "source": [
    "Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c5c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None  # store the first dataset for fire labels\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    \n",
    "    # Daily spatial mean (skip NaNs)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    \n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset with fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Temperature dataset\n",
    "# --------------------\n",
    "temp_file = r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_regrid.nc\"\n",
    "ds_temp = xr.open_dataset(temp_file)\n",
    "\n",
    "# Build datetime index\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    [f\"{y}-{m:02d}-{d:02d}\" for y in years for m in months for d in days],\n",
    "    errors=\"coerce\"\n",
    ").dropna()\n",
    "\n",
    "# Stack Year, Month, Day into a single dimension\n",
    "ds_temp = ds_temp.stack(date=(\"Year\",\"Month\",\"Day\"))\n",
    "ds_temp = ds_temp.assign_coords(time=(\"date\", time_index))\n",
    "ds_temp = ds_temp.swap_dims({\"date\":\"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean temperature (°C, mean across grid)\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\",\"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Portugal\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Temperature\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Temperature\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build combined DataFrame (pollutants + temperature)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_temperature_correlations_by_fire_label_Portugal.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3636e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None  # store the first dataset for fire labels\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    \n",
    "    # Daily spatial mean (skip NaNs)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    \n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset with fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Temperature dataset\n",
    "# --------------------\n",
    "temp_file = r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_regrid.nc\"\n",
    "ds_temp = xr.open_dataset(temp_file)\n",
    "\n",
    "# Build datetime index\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    [f\"{y}-{m:02d}-{d:02d}\" for y in years for m in months for d in days],\n",
    "    errors=\"coerce\"\n",
    ").dropna()\n",
    "\n",
    "# Stack Year, Month, Day into a single dimension\n",
    "ds_temp = ds_temp.stack(date=(\"Year\",\"Month\",\"Day\"))\n",
    "ds_temp = ds_temp.assign_coords(time=(\"date\", time_index))\n",
    "ds_temp = ds_temp.swap_dims({\"date\":\"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean temperature (°C, mean across grid)\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\",\"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Italy\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Temperature\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Temperature\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build combined DataFrame (pollutants + temperature)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_temperature_correlations_by_fire_label_Italy.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeceb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None  # store the first dataset for fire labels\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    \n",
    "    # Daily spatial mean (skip NaNs)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    \n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset with fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Temperature dataset\n",
    "# --------------------\n",
    "temp_file = r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_regrid.nc\"\n",
    "ds_temp = xr.open_dataset(temp_file)\n",
    "\n",
    "# Build datetime index\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    [f\"{y}-{m:02d}-{d:02d}\" for y in years for m in months for d in days],\n",
    "    errors=\"coerce\"\n",
    ").dropna()\n",
    "\n",
    "# Stack Year, Month, Day into a single dimension\n",
    "ds_temp = ds_temp.stack(date=(\"Year\",\"Month\",\"Day\"))\n",
    "ds_temp = ds_temp.assign_coords(time=(\"date\", time_index))\n",
    "ds_temp = ds_temp.swap_dims({\"date\":\"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean temperature (°C, mean across grid)\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\",\"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Spain\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Temperature\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Temperature\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build combined DataFrame (pollutants + temperature)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_temperature_correlations_by_fire_label_Spain.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6794a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None  # store the first dataset for fire labels\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    \n",
    "    # Daily spatial mean (skip NaNs)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    \n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset with fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Temperature dataset\n",
    "# --------------------\n",
    "temp_file = r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_regrid.nc\"\n",
    "ds_temp = xr.open_dataset(temp_file)\n",
    "\n",
    "# Build datetime index\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    [f\"{y}-{m:02d}-{d:02d}\" for y in years for m in months for d in days],\n",
    "    errors=\"coerce\"\n",
    ").dropna()\n",
    "\n",
    "# Stack Year, Month, Day into a single dimension\n",
    "ds_temp = ds_temp.stack(date=(\"Year\",\"Month\",\"Day\"))\n",
    "ds_temp = ds_temp.assign_coords(time=(\"date\", time_index))\n",
    "ds_temp = ds_temp.swap_dims({\"date\":\"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean temperature (°C, mean across grid)\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\",\"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Greece\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Temperature\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Temperature\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build combined DataFrame (pollutants + temperature)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_temperature_correlations_by_fire_label_Greece.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
