{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5837e9",
   "metadata": {},
   "source": [
    "mean +- standard error of mean of pollutants on day without fire, with fire and up to 5 days after fire outbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52216297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Portugal'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000    \n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Portugal):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec16065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Italy'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Italy):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5400942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Spain'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Spain):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff276096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Dictionary of pollutants and their NetCDF file paths\n",
    "pollutant_files = {\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "# Human-readable labels\n",
    "label_names = {\n",
    "    0: \"No fire\",\n",
    "    1: \"Day 0 (Fire outbreak)\",\n",
    "    2: \"Day 1\",\n",
    "    3: \"Day 2\",\n",
    "    4: \"Day 3\",\n",
    "    5: \"Day 4\",\n",
    "    6: \"Day 5\",\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = { \"Label\": list(label_names.values()) }\n",
    "\n",
    "# Loop over pollutants\n",
    "for pollutant, filepath in pollutant_files.items():\n",
    "    ds = xr.open_dataset(filepath)\n",
    "\n",
    "    data = ds['Mean']  # pollutant values\n",
    "    labels = ds['fire_label_Greece'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "    mean_list, sem_list = [], []\n",
    "\n",
    "    # Loop over fire labels\n",
    "    for label in label_names.keys():\n",
    "        mask = labels == label\n",
    "        masked_data = data.where(mask)\n",
    "\n",
    "        # Stats across time per grid cell\n",
    "        mean = masked_data.mean(dim='time', skipna=True)\n",
    "        std = masked_data.std(dim='time', skipna=True)\n",
    "        count = masked_data.count(dim='time')\n",
    "        sem = std / np.sqrt(count)\n",
    "\n",
    "        # Spatial average\n",
    "        mean_val = mean.mean(skipna=True).item()\n",
    "        sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "        # Convert CO mg/m³ → µg/m³\n",
    "        if pollutant == \"CO\":\n",
    "            mean_val *= 1000\n",
    "            sem_val *= 1000\n",
    "\n",
    "        mean_list.append(mean_val)\n",
    "        sem_list.append(sem_val)\n",
    "\n",
    "    # Add columns for this pollutant\n",
    "    results[f\"{pollutant} Mean (µg/m³)\"] = mean_list\n",
    "    results[f\"{pollutant} SEM (µg/m³)\"] = sem_list\n",
    "\n",
    "# Convert to DataFrame for pretty table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nPollutant concentrations by fire label (spatial average across Greece):\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e2468",
   "metadata": {},
   "source": [
    "Divide daily concentrations of pollutants into quartiles Q1 (lowest), Q2, Q3 and Q4 (highest) for days when fires occurred and days they did not - Assess the impact of fire events on the concentration of air pollutants. Calculation of percentage of days (non-wildfire and wildfire) in each of the four qaurtiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b929c10",
   "metadata": {},
   "source": [
    "Splits pollutant concentrations into quartiles (25% intervals) separately for fire and no-fire cases:\n",
    "\n",
    "Q1 = lowest 25%\n",
    "\n",
    "Q2 = 25–50%\n",
    "\n",
    "Q3 = 50–75%\n",
    "\n",
    "Q4 = highest 25%\n",
    "\n",
    "CO IS NOW IN THE SAME UNITS AS THE OTHER POLLUTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1225e060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fire days quartile ranges:\n",
      "  pollutant        min      Q1_cut      median      Q3_cut           max\n",
      "0        CO  79.890615  162.723221  220.085429  342.843107  18765.392899\n",
      "1     PM2.5   1.287711    9.214372   17.306115   35.084427   1031.491800\n",
      "2      PM10   1.627074   13.339724   24.233247   48.764641   1353.121434\n",
      "3       NO2   1.084791    4.959616    8.057715   12.552080    191.778204\n",
      "4        NO   0.040122    0.217520    0.539270    2.492805    426.067570\n",
      "\n",
      "Non-fire days quartile ranges:\n",
      "  pollutant        min      Q1_cut      median      Q3_cut          max\n",
      "0        CO  80.523754  134.016262  158.051344  187.555439  1939.176795\n",
      "1     PM2.5   1.496552    5.984403    8.214316   11.666649   167.079925\n",
      "2      PM10   2.187659    9.074594   12.509280   17.444711   228.303942\n",
      "3       NO2   1.266539    3.743787    5.070246    6.732405    27.635693\n",
      "4        NO   0.012126    0.165539    0.288293    0.614134    34.866279\n",
      "\n",
      "Fire days counts & percentages:\n",
      "   quartile  count pollutant  percentage\n",
      "0        Q1    434        CO   25.028835\n",
      "1        Q2    433        CO   24.971165\n",
      "2        Q3    433        CO   24.971165\n",
      "3        Q4    434        CO   25.028835\n",
      "4        Q1    434     PM2.5   25.028835\n",
      "5        Q2    433     PM2.5   24.971165\n",
      "6        Q3    433     PM2.5   24.971165\n",
      "7        Q4    434     PM2.5   25.028835\n",
      "8        Q1    434      PM10   25.028835\n",
      "9        Q2    433      PM10   24.971165\n",
      "10       Q3    433      PM10   24.971165\n",
      "11       Q4    434      PM10   25.028835\n",
      "12       Q1    434       NO2   25.028835\n",
      "13       Q2    433       NO2   24.971165\n",
      "14       Q3    433       NO2   24.971165\n",
      "15       Q4    434       NO2   25.028835\n",
      "16       Q1    434        NO   25.028835\n",
      "17       Q2    433        NO   24.971165\n",
      "18       Q3    433        NO   24.971165\n",
      "19       Q4    434        NO   25.028835\n",
      "\n",
      "Non-fire days counts & percentages:\n",
      "   quartile  count pollutant  percentage\n",
      "0        Q1   2009        CO        25.0\n",
      "1        Q2   2009        CO        25.0\n",
      "2        Q3   2009        CO        25.0\n",
      "3        Q4   2009        CO        25.0\n",
      "4        Q1   2009     PM2.5        25.0\n",
      "5        Q2   2009     PM2.5        25.0\n",
      "6        Q3   2009     PM2.5        25.0\n",
      "7        Q4   2009     PM2.5        25.0\n",
      "8        Q1   2009      PM10        25.0\n",
      "9        Q2   2009      PM10        25.0\n",
      "10       Q3   2009      PM10        25.0\n",
      "11       Q4   2009      PM10        25.0\n",
      "12       Q1   2009       NO2        25.0\n",
      "13       Q2   2009       NO2        25.0\n",
      "14       Q3   2009       NO2        25.0\n",
      "15       Q4   2009       NO2        25.0\n",
      "16       Q1   2009        NO        25.0\n",
      "17       Q2   2009        NO        25.0\n",
      "18       Q3   2009        NO        25.0\n",
      "19       Q4   2009        NO        25.0\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "fire_results = []\n",
    "nofire_results = []\n",
    "fire_ranges = []\n",
    "nofire_ranges = []\n",
    "fire_counts = []\n",
    "nofire_counts = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    pollutant = ds[\"Mean\"]\n",
    "    fire_flag = ds[\"fire_binary_Portugal\"]\n",
    "\n",
    "    # Convert CO units\n",
    "    if pol_name == \"CO\":\n",
    "        pollutant = pollutant * 1000\n",
    "\n",
    "    df = xr.Dataset({\"pollutant\": pollutant, \"fire\": fire_flag}).to_dataframe().reset_index()\n",
    "\n",
    "    # --- FIRE DAYS ---\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_fire_daily = (\n",
    "        df_fire.groupby(df_fire[\"time\"].dt.normalize())\n",
    "        .apply(lambda sub: pd.Series([sub[\"pollutant\"].mean(), len(sub)], index=[\"pollutant_fire_mean\",\"pixel_count\"]))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_fire_daily[\"pollutant\"] = pol_name\n",
    "    fire_results.append(df_fire_daily)\n",
    "\n",
    "    # Quartiles for fire days\n",
    "    values = df_fire_daily[\"pollutant_fire_mean\"].dropna()\n",
    "    if len(values) > 0:\n",
    "        if len(values.unique()) > 1:\n",
    "            df_fire_daily[\"quartile\"] = pd.qcut(values, q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"], duplicates=\"drop\")\n",
    "        else:\n",
    "            df_fire_daily[\"quartile\"] = \"Q1\"\n",
    "\n",
    "        # Counts & percentages\n",
    "        summary_counts = df_fire_daily[\"quartile\"].value_counts().sort_index().reset_index()\n",
    "        summary_counts.columns = [\"quartile\",\"count\"]\n",
    "        summary_counts[\"pollutant\"] = pol_name\n",
    "        summary_counts[\"percentage\"] = summary_counts[\"count\"] / summary_counts[\"count\"].sum() * 100\n",
    "        fire_counts.append(summary_counts)\n",
    "\n",
    "        # Quartile ranges\n",
    "        edges = np.percentile(values, [0,25,50,75,100])\n",
    "        fire_ranges.append({\n",
    "            \"pollutant\": pol_name,\n",
    "            \"min\": edges[0],\n",
    "            \"Q1_cut\": edges[1],\n",
    "            \"median\": edges[2],\n",
    "            \"Q3_cut\": edges[3],\n",
    "            \"max\": edges[4]\n",
    "        })\n",
    "\n",
    "    # --- NON-FIRE DAYS ---\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "    df_nofire_daily = (\n",
    "        df_nofire.groupby(df_nofire[\"time\"].dt.normalize())\n",
    "        .apply(lambda sub: pd.Series([sub[\"pollutant\"].mean(), len(sub)], index=[\"pollutant_nofire_mean\",\"pixel_count\"]))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_nofire_daily[\"pollutant\"] = pol_name\n",
    "    nofire_results.append(df_nofire_daily)\n",
    "\n",
    "    # Quartiles for non-fire days\n",
    "    values = df_nofire_daily[\"pollutant_nofire_mean\"].dropna()\n",
    "    if len(values) > 0:\n",
    "        if len(values.unique()) > 1:\n",
    "            df_nofire_daily[\"quartile\"] = pd.qcut(values, q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"], duplicates=\"drop\")\n",
    "        else:\n",
    "            df_nofire_daily[\"quartile\"] = \"Q1\"\n",
    "\n",
    "        # Counts & percentages\n",
    "        summary_counts = df_nofire_daily[\"quartile\"].value_counts().sort_index().reset_index()\n",
    "        summary_counts.columns = [\"quartile\",\"count\"]\n",
    "        summary_counts[\"pollutant\"] = pol_name\n",
    "        summary_counts[\"percentage\"] = summary_counts[\"count\"] / summary_counts[\"count\"].sum() * 100\n",
    "        nofire_counts.append(summary_counts)\n",
    "\n",
    "        # Quartile ranges\n",
    "        edges = np.percentile(values, [0,25,50,75,100])\n",
    "        nofire_ranges.append({\n",
    "            \"pollutant\": pol_name,\n",
    "            \"min\": edges[0],\n",
    "            \"Q1_cut\": edges[1],\n",
    "            \"median\": edges[2],\n",
    "            \"Q3_cut\": edges[3],\n",
    "            \"max\": edges[4]\n",
    "        })\n",
    "\n",
    "# --- Combine results ---\n",
    "fire_days_table = pd.concat(fire_results, ignore_index=True)\n",
    "nofire_days_table = pd.concat(nofire_results, ignore_index=True)\n",
    "\n",
    "fire_ranges_table = pd.DataFrame(fire_ranges)\n",
    "nofire_ranges_table = pd.DataFrame(nofire_ranges)\n",
    "\n",
    "fire_counts_table = pd.concat(fire_counts, ignore_index=True)\n",
    "nofire_counts_table = pd.concat(nofire_counts, ignore_index=True)\n",
    "\n",
    "print(\"\\nFire days quartile ranges:\")\n",
    "print(fire_ranges_table)\n",
    "print(\"\\nNon-fire days quartile ranges:\")\n",
    "print(nofire_ranges_table)\n",
    "\n",
    "print(\"\\nFire days counts & percentages:\")\n",
    "print(fire_counts_table)\n",
    "print(\"\\nNon-fire days counts & percentages:\")\n",
    "print(nofire_counts_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e1215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac78fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3505f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebe2720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fire days quartile ranges:\n",
      "  pollutant         min      Q1_cut      median      Q3_cut          max\n",
      "0        CO  104.324758  155.944086  187.315612  238.667185  1263.977073\n",
      "1     PM2.5    0.112157    9.175309   13.827742   20.742627   168.981193\n",
      "2      PM10    0.213340   13.147116   19.750781   29.103967   237.304443\n",
      "3       NO2    0.408984    4.000867    6.822248   10.684817    44.618905\n",
      "4        NO    0.019623    0.165399    0.329950    0.846355    77.868684\n",
      "\n",
      "Non-fire days quartile ranges:\n",
      "  pollutant         min      Q1_cut      median      Q3_cut         max\n",
      "0        CO  118.462302  176.376531  208.684938  259.593209  571.495006\n",
      "1     PM2.5    3.509969   10.416339   13.470428   17.741813   65.550824\n",
      "2      PM10    5.261541   14.979502   19.183497   25.144293   84.677088\n",
      "3       NO2    2.666766    7.068279    9.037292   11.651976   24.449468\n",
      "4        NO    0.075712    0.582060    1.224258    2.846164   24.942879\n",
      "\n",
      "Fire days counts & percentages:\n",
      "   quartile  count pollutant  percentage\n",
      "0        Q1    528        CO   25.035562\n",
      "1        Q2    527        CO   24.988146\n",
      "2        Q3    527        CO   24.988146\n",
      "3        Q4    527        CO   24.988146\n",
      "4        Q1    528     PM2.5   25.035562\n",
      "5        Q2    527     PM2.5   24.988146\n",
      "6        Q3    527     PM2.5   24.988146\n",
      "7        Q4    527     PM2.5   24.988146\n",
      "8        Q1    528      PM10   25.035562\n",
      "9        Q2    527      PM10   24.988146\n",
      "10       Q3    527      PM10   24.988146\n",
      "11       Q4    527      PM10   24.988146\n",
      "12       Q1    528       NO2   25.035562\n",
      "13       Q2    527       NO2   24.988146\n",
      "14       Q3    527       NO2   24.988146\n",
      "15       Q4    527       NO2   24.988146\n",
      "16       Q1    528        NO   25.035562\n",
      "17       Q2    527        NO   24.988146\n",
      "18       Q3    527        NO   24.988146\n",
      "19       Q4    527        NO   24.988146\n",
      "\n",
      "Non-fire days counts & percentages:\n",
      "   quartile  count pollutant  percentage\n",
      "0        Q1   2009        CO        25.0\n",
      "1        Q2   2009        CO        25.0\n",
      "2        Q3   2009        CO        25.0\n",
      "3        Q4   2009        CO        25.0\n",
      "4        Q1   2009     PM2.5        25.0\n",
      "5        Q2   2009     PM2.5        25.0\n",
      "6        Q3   2009     PM2.5        25.0\n",
      "7        Q4   2009     PM2.5        25.0\n",
      "8        Q1   2009      PM10        25.0\n",
      "9        Q2   2009      PM10        25.0\n",
      "10       Q3   2009      PM10        25.0\n",
      "11       Q4   2009      PM10        25.0\n",
      "12       Q1   2009       NO2        25.0\n",
      "13       Q2   2009       NO2        25.0\n",
      "14       Q3   2009       NO2        25.0\n",
      "15       Q4   2009       NO2        25.0\n",
      "16       Q1   2009        NO        25.0\n",
      "17       Q2   2009        NO        25.0\n",
      "18       Q3   2009        NO        25.0\n",
      "19       Q4   2009        NO        25.0\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "fire_results = []\n",
    "nofire_results = []\n",
    "fire_ranges = []\n",
    "nofire_ranges = []\n",
    "fire_counts = []\n",
    "nofire_counts = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    pollutant = ds[\"Mean\"]\n",
    "    fire_flag = ds[\"fire_binary_Italy\"]\n",
    "\n",
    "    # Convert CO units\n",
    "    if pol_name == \"CO\":\n",
    "        pollutant = pollutant * 1000\n",
    "\n",
    "    df = xr.Dataset({\"pollutant\": pollutant, \"fire\": fire_flag}).to_dataframe().reset_index()\n",
    "\n",
    "    # --- FIRE DAYS ---\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_fire_daily = (\n",
    "        df_fire.groupby(df_fire[\"time\"].dt.normalize())\n",
    "        .apply(lambda sub: pd.Series([sub[\"pollutant\"].mean(), len(sub)], index=[\"pollutant_fire_mean\",\"pixel_count\"]))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_fire_daily[\"pollutant\"] = pol_name\n",
    "    fire_results.append(df_fire_daily)\n",
    "\n",
    "    # Quartiles for fire days\n",
    "    values = df_fire_daily[\"pollutant_fire_mean\"].dropna()\n",
    "    if len(values) > 0:\n",
    "        if len(values.unique()) > 1:\n",
    "            df_fire_daily[\"quartile\"] = pd.qcut(values, q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"], duplicates=\"drop\")\n",
    "        else:\n",
    "            df_fire_daily[\"quartile\"] = \"Q1\"\n",
    "\n",
    "        # Counts & percentages\n",
    "        summary_counts = df_fire_daily[\"quartile\"].value_counts().sort_index().reset_index()\n",
    "        summary_counts.columns = [\"quartile\",\"count\"]\n",
    "        summary_counts[\"pollutant\"] = pol_name\n",
    "        summary_counts[\"percentage\"] = summary_counts[\"count\"] / summary_counts[\"count\"].sum() * 100\n",
    "        fire_counts.append(summary_counts)\n",
    "\n",
    "        # Quartile ranges\n",
    "        edges = np.percentile(values, [0,25,50,75,100])\n",
    "        fire_ranges.append({\n",
    "            \"pollutant\": pol_name,\n",
    "            \"min\": edges[0],\n",
    "            \"Q1_cut\": edges[1],\n",
    "            \"median\": edges[2],\n",
    "            \"Q3_cut\": edges[3],\n",
    "            \"max\": edges[4]\n",
    "        })\n",
    "\n",
    "    # --- NON-FIRE DAYS ---\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "    df_nofire_daily = (\n",
    "        df_nofire.groupby(df_nofire[\"time\"].dt.normalize())\n",
    "        .apply(lambda sub: pd.Series([sub[\"pollutant\"].mean(), len(sub)], index=[\"pollutant_nofire_mean\",\"pixel_count\"]))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_nofire_daily[\"pollutant\"] = pol_name\n",
    "    nofire_results.append(df_nofire_daily)\n",
    "\n",
    "    # Quartiles for non-fire days\n",
    "    values = df_nofire_daily[\"pollutant_nofire_mean\"].dropna()\n",
    "    if len(values) > 0:\n",
    "        if len(values.unique()) > 1:\n",
    "            df_nofire_daily[\"quartile\"] = pd.qcut(values, q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"], duplicates=\"drop\")\n",
    "        else:\n",
    "            df_nofire_daily[\"quartile\"] = \"Q1\"\n",
    "\n",
    "        # Counts & percentages\n",
    "        summary_counts = df_nofire_daily[\"quartile\"].value_counts().sort_index().reset_index()\n",
    "        summary_counts.columns = [\"quartile\",\"count\"]\n",
    "        summary_counts[\"pollutant\"] = pol_name\n",
    "        summary_counts[\"percentage\"] = summary_counts[\"count\"] / summary_counts[\"count\"].sum() * 100\n",
    "        nofire_counts.append(summary_counts)\n",
    "\n",
    "        # Quartile ranges\n",
    "        edges = np.percentile(values, [0,25,50,75,100])\n",
    "        nofire_ranges.append({\n",
    "            \"pollutant\": pol_name,\n",
    "            \"min\": edges[0],\n",
    "            \"Q1_cut\": edges[1],\n",
    "            \"median\": edges[2],\n",
    "            \"Q3_cut\": edges[3],\n",
    "            \"max\": edges[4]\n",
    "        })\n",
    "\n",
    "# --- Combine results ---\n",
    "fire_days_table = pd.concat(fire_results, ignore_index=True)\n",
    "nofire_days_table = pd.concat(nofire_results, ignore_index=True)\n",
    "\n",
    "fire_ranges_table = pd.DataFrame(fire_ranges)\n",
    "nofire_ranges_table = pd.DataFrame(nofire_ranges)\n",
    "\n",
    "fire_counts_table = pd.concat(fire_counts, ignore_index=True)\n",
    "nofire_counts_table = pd.concat(nofire_counts, ignore_index=True)\n",
    "\n",
    "print(\"\\nFire days quartile ranges:\")\n",
    "print(fire_ranges_table)\n",
    "print(\"\\nNon-fire days quartile ranges:\")\n",
    "print(nofire_ranges_table)\n",
    "\n",
    "print(\"\\nFire days counts & percentages:\")\n",
    "print(fire_counts_table)\n",
    "print(\"\\nNon-fire days counts & percentages:\")\n",
    "print(nofire_counts_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a513fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fire days quartile ranges:\n",
      "  pollutant         min      Q1_cut      median      Q3_cut          max\n",
      "0        CO  100.131964  164.717975  197.501197  248.504299  7014.863797\n",
      "1     PM2.5    0.178621    9.968379   14.676985   21.846085   583.687717\n",
      "2      PM10    0.249634   13.977567   20.540713   30.429758   781.713908\n",
      "3       NO2    0.326040    3.158598    6.123831   10.907623    94.105034\n",
      "4        NO    0.007587    0.106439    0.247242    0.956303   155.044650\n",
      "\n",
      "Non-fire days quartile ranges:\n",
      "  pollutant         min      Q1_cut      median      Q3_cut         max\n",
      "0        CO  108.212757  155.479401  174.008595  199.646956  832.200378\n",
      "1     PM2.5    0.788244    8.005333   10.765755   14.316851  136.456497\n",
      "2      PM10    1.143472   11.462330   15.281285   20.201884  190.624863\n",
      "3       NO2    1.140573    3.042641    3.904628    5.083060   14.865463\n",
      "4        NO    0.040150    0.150855    0.300552    0.635029    5.818358\n",
      "\n",
      "Fire days counts & percentages:\n",
      "   quartile  count pollutant  percentage\n",
      "0        Q1    532        CO   25.035294\n",
      "1        Q2    531        CO   24.988235\n",
      "2        Q3    531        CO   24.988235\n",
      "3        Q4    531        CO   24.988235\n",
      "4        Q1    532     PM2.5   25.035294\n",
      "5        Q2    531     PM2.5   24.988235\n",
      "6        Q3    531     PM2.5   24.988235\n",
      "7        Q4    531     PM2.5   24.988235\n",
      "8        Q1    532      PM10   25.035294\n",
      "9        Q2    531      PM10   24.988235\n",
      "10       Q3    531      PM10   24.988235\n",
      "11       Q4    531      PM10   24.988235\n",
      "12       Q1    532       NO2   25.035294\n",
      "13       Q2    531       NO2   24.988235\n",
      "14       Q3    531       NO2   24.988235\n",
      "15       Q4    531       NO2   24.988235\n",
      "16       Q1    532        NO   25.035294\n",
      "17       Q2    531        NO   24.988235\n",
      "18       Q3    531        NO   24.988235\n",
      "19       Q4    531        NO   24.988235\n",
      "\n",
      "Non-fire days counts & percentages:\n",
      "   quartile  count pollutant  percentage\n",
      "0        Q1   2009        CO        25.0\n",
      "1        Q2   2009        CO        25.0\n",
      "2        Q3   2009        CO        25.0\n",
      "3        Q4   2009        CO        25.0\n",
      "4        Q1   2009     PM2.5        25.0\n",
      "5        Q2   2009     PM2.5        25.0\n",
      "6        Q3   2009     PM2.5        25.0\n",
      "7        Q4   2009     PM2.5        25.0\n",
      "8        Q1   2009      PM10        25.0\n",
      "9        Q2   2009      PM10        25.0\n",
      "10       Q3   2009      PM10        25.0\n",
      "11       Q4   2009      PM10        25.0\n",
      "12       Q1   2009       NO2        25.0\n",
      "13       Q2   2009       NO2        25.0\n",
      "14       Q3   2009       NO2        25.0\n",
      "15       Q4   2009       NO2        25.0\n",
      "16       Q1   2009        NO        25.0\n",
      "17       Q2   2009        NO        25.0\n",
      "18       Q3   2009        NO        25.0\n",
      "19       Q4   2009        NO        25.0\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "fire_results = []\n",
    "nofire_results = []\n",
    "fire_ranges = []\n",
    "nofire_ranges = []\n",
    "fire_counts = []\n",
    "nofire_counts = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    pollutant = ds[\"Mean\"]\n",
    "    fire_flag = ds[\"fire_binary_Greece\"]\n",
    "\n",
    "    # Convert CO units\n",
    "    if pol_name == \"CO\":\n",
    "        pollutant = pollutant * 1000\n",
    "\n",
    "    df = xr.Dataset({\"pollutant\": pollutant, \"fire\": fire_flag}).to_dataframe().reset_index()\n",
    "\n",
    "    # --- FIRE DAYS ---\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_fire_daily = (\n",
    "        df_fire.groupby(df_fire[\"time\"].dt.normalize())\n",
    "        .apply(lambda sub: pd.Series([sub[\"pollutant\"].mean(), len(sub)], index=[\"pollutant_fire_mean\",\"pixel_count\"]))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_fire_daily[\"pollutant\"] = pol_name\n",
    "    fire_results.append(df_fire_daily)\n",
    "\n",
    "    # Quartiles for fire days\n",
    "    values = df_fire_daily[\"pollutant_fire_mean\"].dropna()\n",
    "    if len(values) > 0:\n",
    "        if len(values.unique()) > 1:\n",
    "            df_fire_daily[\"quartile\"] = pd.qcut(values, q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"], duplicates=\"drop\")\n",
    "        else:\n",
    "            df_fire_daily[\"quartile\"] = \"Q1\"\n",
    "\n",
    "        # Counts & percentages\n",
    "        summary_counts = df_fire_daily[\"quartile\"].value_counts().sort_index().reset_index()\n",
    "        summary_counts.columns = [\"quartile\",\"count\"]\n",
    "        summary_counts[\"pollutant\"] = pol_name\n",
    "        summary_counts[\"percentage\"] = summary_counts[\"count\"] / summary_counts[\"count\"].sum() * 100\n",
    "        fire_counts.append(summary_counts)\n",
    "\n",
    "        # Quartile ranges\n",
    "        edges = np.percentile(values, [0,25,50,75,100])\n",
    "        fire_ranges.append({\n",
    "            \"pollutant\": pol_name,\n",
    "            \"min\": edges[0],\n",
    "            \"Q1_cut\": edges[1],\n",
    "            \"median\": edges[2],\n",
    "            \"Q3_cut\": edges[3],\n",
    "            \"max\": edges[4]\n",
    "        })\n",
    "\n",
    "    # --- NON-FIRE DAYS ---\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "    df_nofire_daily = (\n",
    "        df_nofire.groupby(df_nofire[\"time\"].dt.normalize())\n",
    "        .apply(lambda sub: pd.Series([sub[\"pollutant\"].mean(), len(sub)], index=[\"pollutant_nofire_mean\",\"pixel_count\"]))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_nofire_daily[\"pollutant\"] = pol_name\n",
    "    nofire_results.append(df_nofire_daily)\n",
    "\n",
    "    # Quartiles for non-fire days\n",
    "    values = df_nofire_daily[\"pollutant_nofire_mean\"].dropna()\n",
    "    if len(values) > 0:\n",
    "        if len(values.unique()) > 1:\n",
    "            df_nofire_daily[\"quartile\"] = pd.qcut(values, q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"], duplicates=\"drop\")\n",
    "        else:\n",
    "            df_nofire_daily[\"quartile\"] = \"Q1\"\n",
    "\n",
    "        # Counts & percentages\n",
    "        summary_counts = df_nofire_daily[\"quartile\"].value_counts().sort_index().reset_index()\n",
    "        summary_counts.columns = [\"quartile\",\"count\"]\n",
    "        summary_counts[\"pollutant\"] = pol_name\n",
    "        summary_counts[\"percentage\"] = summary_counts[\"count\"] / summary_counts[\"count\"].sum() * 100\n",
    "        nofire_counts.append(summary_counts)\n",
    "\n",
    "        # Quartile ranges\n",
    "        edges = np.percentile(values, [0,25,50,75,100])\n",
    "        nofire_ranges.append({\n",
    "            \"pollutant\": pol_name,\n",
    "            \"min\": edges[0],\n",
    "            \"Q1_cut\": edges[1],\n",
    "            \"median\": edges[2],\n",
    "            \"Q3_cut\": edges[3],\n",
    "            \"max\": edges[4]\n",
    "        })\n",
    "\n",
    "# --- Combine results ---\n",
    "fire_days_table = pd.concat(fire_results, ignore_index=True)\n",
    "nofire_days_table = pd.concat(nofire_results, ignore_index=True)\n",
    "\n",
    "fire_ranges_table = pd.DataFrame(fire_ranges)\n",
    "nofire_ranges_table = pd.DataFrame(nofire_ranges)\n",
    "\n",
    "fire_counts_table = pd.concat(fire_counts, ignore_index=True)\n",
    "nofire_counts_table = pd.concat(nofire_counts, ignore_index=True)\n",
    "\n",
    "print(\"\\nFire days quartile ranges:\")\n",
    "print(fire_ranges_table)\n",
    "print(\"\\nNon-fire days quartile ranges:\")\n",
    "print(nofire_ranges_table)\n",
    "\n",
    "print(\"\\nFire days counts & percentages:\")\n",
    "print(fire_counts_table)\n",
    "print(\"\\nNon-fire days counts & percentages:\")\n",
    "print(nofire_counts_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7576315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fire days quartile ranges:\n",
      "  pollutant        min      Q1_cut      median      Q3_cut          max\n",
      "0        CO  87.836192  155.936416  202.287439  294.528603  7987.803115\n",
      "1     PM2.5   1.033568    8.876236   14.642410   26.098120   714.536468\n",
      "2      PM10   1.472035   12.715223   20.591426   36.500962   985.934567\n",
      "3       NO2   0.285172    4.923815    7.990631   12.346320    65.252311\n",
      "4        NO   0.019482    0.214687    0.500822    2.148763   213.958214\n",
      "\n",
      "Non-fire days quartile ranges:\n",
      "  pollutant        min      Q1_cut      median      Q3_cut         max\n",
      "0        CO  97.030085  146.767654  170.192185  202.671048  440.381860\n",
      "1     PM2.5   2.245757    7.146325    9.329687   12.494731   73.506646\n",
      "2      PM10   3.429071   10.554788   13.589190   17.800433   92.609943\n",
      "3       NO2   1.797235    4.633263    6.098844    8.364016   19.760695\n",
      "4        NO   0.055706    0.264315    0.516651    1.214280   11.444273\n",
      "\n",
      "Fire days counts & percentages:\n",
      "   quartile  count pollutant  percentage\n",
      "0        Q1    644        CO   25.029149\n",
      "1        Q2    643        CO   24.990284\n",
      "2        Q3    643        CO   24.990284\n",
      "3        Q4    643        CO   24.990284\n",
      "4        Q1    644     PM2.5   25.029149\n",
      "5        Q2    643     PM2.5   24.990284\n",
      "6        Q3    643     PM2.5   24.990284\n",
      "7        Q4    643     PM2.5   24.990284\n",
      "8        Q1    644      PM10   25.029149\n",
      "9        Q2    643      PM10   24.990284\n",
      "10       Q3    643      PM10   24.990284\n",
      "11       Q4    643      PM10   24.990284\n",
      "12       Q1    644       NO2   25.029149\n",
      "13       Q2    643       NO2   24.990284\n",
      "14       Q3    643       NO2   24.990284\n",
      "15       Q4    643       NO2   24.990284\n",
      "16       Q1    644        NO   25.029149\n",
      "17       Q2    643        NO   24.990284\n",
      "18       Q3    643        NO   24.990284\n",
      "19       Q4    643        NO   24.990284\n",
      "\n",
      "Non-fire days counts & percentages:\n",
      "   quartile  count pollutant  percentage\n",
      "0        Q1   2009        CO        25.0\n",
      "1        Q2   2009        CO        25.0\n",
      "2        Q3   2009        CO        25.0\n",
      "3        Q4   2009        CO        25.0\n",
      "4        Q1   2009     PM2.5        25.0\n",
      "5        Q2   2009     PM2.5        25.0\n",
      "6        Q3   2009     PM2.5        25.0\n",
      "7        Q4   2009     PM2.5        25.0\n",
      "8        Q1   2009      PM10        25.0\n",
      "9        Q2   2009      PM10        25.0\n",
      "10       Q3   2009      PM10        25.0\n",
      "11       Q4   2009      PM10        25.0\n",
      "12       Q1   2009       NO2        25.0\n",
      "13       Q2   2009       NO2        25.0\n",
      "14       Q3   2009       NO2        25.0\n",
      "15       Q4   2009       NO2        25.0\n",
      "16       Q1   2009        NO        25.0\n",
      "17       Q2   2009        NO        25.0\n",
      "18       Q3   2009        NO        25.0\n",
      "19       Q4   2009        NO        25.0\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "fire_results = []\n",
    "nofire_results = []\n",
    "fire_ranges = []\n",
    "nofire_ranges = []\n",
    "fire_counts = []\n",
    "nofire_counts = []\n",
    "\n",
    "for pol_name, file_path in files.items():\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    pollutant = ds[\"Mean\"]\n",
    "    fire_flag = ds[\"fire_binary_Spain\"]\n",
    "\n",
    "    # Convert CO units\n",
    "    if pol_name == \"CO\":\n",
    "        pollutant = pollutant * 1000\n",
    "\n",
    "    df = xr.Dataset({\"pollutant\": pollutant, \"fire\": fire_flag}).to_dataframe().reset_index()\n",
    "\n",
    "    # --- FIRE DAYS ---\n",
    "    df_fire = df[df[\"fire\"] == 1].copy()\n",
    "    df_fire_daily = (\n",
    "        df_fire.groupby(df_fire[\"time\"].dt.normalize())\n",
    "        .apply(lambda sub: pd.Series([sub[\"pollutant\"].mean(), len(sub)], index=[\"pollutant_fire_mean\",\"pixel_count\"]))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_fire_daily[\"pollutant\"] = pol_name\n",
    "    fire_results.append(df_fire_daily)\n",
    "\n",
    "    # Quartiles for fire days\n",
    "    values = df_fire_daily[\"pollutant_fire_mean\"].dropna()\n",
    "    if len(values) > 0:\n",
    "        if len(values.unique()) > 1:\n",
    "            df_fire_daily[\"quartile\"] = pd.qcut(values, q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"], duplicates=\"drop\")\n",
    "        else:\n",
    "            df_fire_daily[\"quartile\"] = \"Q1\"\n",
    "\n",
    "        # Counts & percentages\n",
    "        summary_counts = df_fire_daily[\"quartile\"].value_counts().sort_index().reset_index()\n",
    "        summary_counts.columns = [\"quartile\",\"count\"]\n",
    "        summary_counts[\"pollutant\"] = pol_name\n",
    "        summary_counts[\"percentage\"] = summary_counts[\"count\"] / summary_counts[\"count\"].sum() * 100\n",
    "        fire_counts.append(summary_counts)\n",
    "\n",
    "        # Quartile ranges\n",
    "        edges = np.percentile(values, [0,25,50,75,100])\n",
    "        fire_ranges.append({\n",
    "            \"pollutant\": pol_name,\n",
    "            \"min\": edges[0],\n",
    "            \"Q1_cut\": edges[1],\n",
    "            \"median\": edges[2],\n",
    "            \"Q3_cut\": edges[3],\n",
    "            \"max\": edges[4]\n",
    "        })\n",
    "\n",
    "    # --- NON-FIRE DAYS ---\n",
    "    df_nofire = df[df[\"fire\"] == 0].copy()\n",
    "    df_nofire_daily = (\n",
    "        df_nofire.groupby(df_nofire[\"time\"].dt.normalize())\n",
    "        .apply(lambda sub: pd.Series([sub[\"pollutant\"].mean(), len(sub)], index=[\"pollutant_nofire_mean\",\"pixel_count\"]))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_nofire_daily[\"pollutant\"] = pol_name\n",
    "    nofire_results.append(df_nofire_daily)\n",
    "\n",
    "    # Quartiles for non-fire days\n",
    "    values = df_nofire_daily[\"pollutant_nofire_mean\"].dropna()\n",
    "    if len(values) > 0:\n",
    "        if len(values.unique()) > 1:\n",
    "            df_nofire_daily[\"quartile\"] = pd.qcut(values, q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"], duplicates=\"drop\")\n",
    "        else:\n",
    "            df_nofire_daily[\"quartile\"] = \"Q1\"\n",
    "\n",
    "        # Counts & percentages\n",
    "        summary_counts = df_nofire_daily[\"quartile\"].value_counts().sort_index().reset_index()\n",
    "        summary_counts.columns = [\"quartile\",\"count\"]\n",
    "        summary_counts[\"pollutant\"] = pol_name\n",
    "        summary_counts[\"percentage\"] = summary_counts[\"count\"] / summary_counts[\"count\"].sum() * 100\n",
    "        nofire_counts.append(summary_counts)\n",
    "\n",
    "        # Quartile ranges\n",
    "        edges = np.percentile(values, [0,25,50,75,100])\n",
    "        nofire_ranges.append({\n",
    "            \"pollutant\": pol_name,\n",
    "            \"min\": edges[0],\n",
    "            \"Q1_cut\": edges[1],\n",
    "            \"median\": edges[2],\n",
    "            \"Q3_cut\": edges[3],\n",
    "            \"max\": edges[4]\n",
    "        })\n",
    "\n",
    "# --- Combine results ---\n",
    "fire_days_table = pd.concat(fire_results, ignore_index=True)\n",
    "nofire_days_table = pd.concat(nofire_results, ignore_index=True)\n",
    "\n",
    "fire_ranges_table = pd.DataFrame(fire_ranges)\n",
    "nofire_ranges_table = pd.DataFrame(nofire_ranges)\n",
    "\n",
    "fire_counts_table = pd.concat(fire_counts, ignore_index=True)\n",
    "nofire_counts_table = pd.concat(nofire_counts, ignore_index=True)\n",
    "\n",
    "print(\"\\nFire days quartile ranges:\")\n",
    "print(fire_ranges_table)\n",
    "print(\"\\nNon-fire days quartile ranges:\")\n",
    "print(nofire_ranges_table)\n",
    "\n",
    "print(\"\\nFire days counts & percentages:\")\n",
    "print(fire_counts_table)\n",
    "print(\"\\nNon-fire days counts & percentages:\")\n",
    "print(nofire_counts_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb4539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dad21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2aade9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe40ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80132e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681f5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "322fd26f",
   "metadata": {},
   "source": [
    "Pearson correlation performed between meteorological variables and air pollutants, for all days and every label established"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3a6a3b",
   "metadata": {},
   "source": [
    "Understanding the p-values\n",
    "\n",
    "Null hypothesis (H₀): There is no correlation between the variables.\n",
    "\n",
    "Alternative hypothesis (H₁): There is a correlation.\n",
    "\n",
    "p-value: Probability of observing the correlation (or more extreme) if H₀ is true.\n",
    "\n",
    "Interpretation rule of thumb:\n",
    "\n",
    "p < 0.05 → significant: reject the null → correlation is likely real.\n",
    "\n",
    "p ≥ 0.05 → not significant: cannot reject the null → correlation might be due to chance.\n",
    "\n",
    "..................................\n",
    "\n",
    "How to read weak vs strong correlations\n",
    "\n",
    "|r| < 0.1 → negligible\n",
    "\n",
    "0.1 ≤ |r| < 0.3 → weak\n",
    "\n",
    "0.3 ≤ |r| < 0.5 → moderate\n",
    "\n",
    "|r| ≥ 0.5 → strong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ec51b",
   "metadata": {},
   "source": [
    "CONVERT UNITS FOR CO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37287cd9",
   "metadata": {},
   "source": [
    "Wind speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e39a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files (same as before)\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Wind speed dataset (multiple yearly files)\n",
    "# --------------------\n",
    "wind_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_yearly_regridded\\daily_wind_speed_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in wind_files]\n",
    "ds_wind = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_wind = ds_wind.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from stacked coordinates\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": ds_wind[\"Year\"].values, \n",
    "     \"month\": ds_wind[\"Month\"].values, \n",
    "     \"day\": ds_wind[\"Day\"].values},\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_wind = ds_wind.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_wind = ds_wind.assign_coords(time=(\"date\", time_index))\n",
    "ds_wind = ds_wind.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean wind speed\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"Wind_Speed\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks (same as before)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0, 7):\n",
    "    mask = fire_ds[\"fire_label_Portugal\"] == label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\", \"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation functions\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Wind_Speed\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Wind_Speed\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Wind_Speed\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Save results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_wind_correlations_by_fire_label_Portugal.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd112df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_wind[\"Year\"].values\n",
    "months = ds_wind[\"Month\"].values\n",
    "days = ds_wind[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + wind speed)\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"WindSpeed\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21238a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Wind speed dataset (multiple yearly files)\n",
    "# --------------------\n",
    "wind_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_yearly_regridded\\daily_wind_speed_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in wind_files]\n",
    "ds_wind = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_wind = ds_wind.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from stacked coordinates\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": ds_wind[\"Year\"].values, \n",
    "     \"month\": ds_wind[\"Month\"].values, \n",
    "     \"day\": ds_wind[\"Day\"].values},\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_wind = ds_wind.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_wind = ds_wind.assign_coords(time=(\"date\", time_index))\n",
    "ds_wind = ds_wind.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean wind speed\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"Wind_Speed\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Italy\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"WindSpeed\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"WindSpeed\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + wind)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_wind_correlations_by_fire_label_Italy.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_wind[\"Year\"].values\n",
    "months = ds_wind[\"Month\"].values\n",
    "days = ds_wind[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + wind speed)\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"WindSpeed\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20239a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Wind speed dataset (multiple yearly files)\n",
    "# --------------------\n",
    "wind_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_yearly_regridded\\daily_wind_speed_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in wind_files]\n",
    "ds_wind = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_wind = ds_wind.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from stacked coordinates\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": ds_wind[\"Year\"].values, \n",
    "     \"month\": ds_wind[\"Month\"].values, \n",
    "     \"day\": ds_wind[\"Day\"].values},\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_wind = ds_wind.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_wind = ds_wind.assign_coords(time=(\"date\", time_index))\n",
    "ds_wind = ds_wind.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean wind speed\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"Wind_Speed\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Spain\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"WindSpeed\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"WindSpeed\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + wind)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_wind_correlations_by_fire_label_Spain.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89db365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_wind[\"Year\"].values\n",
    "months = ds_wind[\"Month\"].values\n",
    "days = ds_wind[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + wind speed)\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"WindSpeed\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318451be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Wind speed dataset (multiple yearly files)\n",
    "# --------------------\n",
    "wind_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_yearly_regridded\\daily_wind_speed_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in wind_files]\n",
    "ds_wind = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_wind = ds_wind.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from stacked coordinates\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": ds_wind[\"Year\"].values, \n",
    "     \"month\": ds_wind[\"Month\"].values, \n",
    "     \"day\": ds_wind[\"Day\"].values},\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_wind = ds_wind.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_wind = ds_wind.assign_coords(time=(\"date\", time_index))\n",
    "ds_wind = ds_wind.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean wind speed\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"Wind_Speed\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Greece\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"WindSpeed\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"WindSpeed\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + wind)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_wind_correlations_by_fire_label_Greece.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ec22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_wind[\"Year\"].values\n",
    "months = ds_wind[\"Month\"].values\n",
    "days = ds_wind[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + wind speed)\n",
    "wind_ts = ds_wind[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "wind_ts.name = \"WindSpeed\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [wind_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"WindSpeed\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227e7f0",
   "metadata": {},
   "source": [
    "Total Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Precipitation dataset (multiple yearly files)\n",
    "# --------------------\n",
    "precip_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_yearly_regridded\\daily_precipitation_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in precip_files]\n",
    "ds_precip = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_precip = ds_precip.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_precip = ds_precip.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_precip = ds_precip.assign_coords(time=(\"date\", time_index))\n",
    "ds_precip = ds_precip.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean of total precipitation\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0, 7):\n",
    "    mask = fire_ds[\"fire_label_Portugal\"] == label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\", \"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation functions\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Precipitation\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Precipitation\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Save results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_precipitation_correlations_by_fire_label_Portugal.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f48b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + precipitation)\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# 2. Precipitation dataset (multiple yearly files)\n",
    "# --------------------\n",
    "precip_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_yearly_regridded\\daily_precipitation_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in precip_files]\n",
    "ds_precip = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_precip = ds_precip.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_precip = ds_precip.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_precip = ds_precip.assign_coords(time=(\"date\", time_index))\n",
    "ds_precip = ds_precip.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean of total precipitation\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Italy\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\", \"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Precipitation\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Precipitation\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + precipitation)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_precipitation_correlations_by_fire_label_Italy.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b219f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + precipitation)\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9969e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Precipitation dataset (multiple yearly files)\n",
    "# --------------------\n",
    "precip_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_yearly_regridded\\daily_precipitation_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in precip_files]\n",
    "ds_precip = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_precip = ds_precip.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_precip = ds_precip.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_precip = ds_precip.assign_coords(time=(\"date\", time_index))\n",
    "ds_precip = ds_precip.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean of total precipitation\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Spain\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Precipitation\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Precipitation\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + precipitation)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_precipitation_correlations_by_fire_label_Spain.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6243135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + precipitation)\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Precipitation dataset (multiple yearly files)\n",
    "# --------------------\n",
    "precip_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_yearly_regridded\\daily_precipitation_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in precip_files]\n",
    "ds_precip = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_precip = ds_precip.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_precip = ds_precip.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_precip = ds_precip.assign_coords(time=(\"date\", time_index))\n",
    "ds_precip = ds_precip.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean of total precipitation\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Greece\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Precipitation\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Precipitation\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame (pollutants + precipitation)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_precipitation_correlations_by_fire_label_Greece.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_precip[\"Year\"].values\n",
    "months = ds_precip[\"Month\"].values\n",
    "days = ds_precip[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + precipitation)\n",
    "precip_ts = ds_precip[\"Total_Precipitation\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "precip_ts.name = \"Precipitation\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [precip_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Precipitation\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce8d9a",
   "metadata": {},
   "source": [
    "Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292aad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files (same as before)\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Portugal.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Portugal.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Portugal.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Portugal.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Temperature dataset (multiple yearly files)\n",
    "# --------------------\n",
    "temp_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_yearly_regridded\\daily_temperature_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in temp_files]\n",
    "ds_temp = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_temp = ds_temp.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_temp = ds_temp.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_temp = ds_temp.assign_coords(time=(\"date\", time_index))\n",
    "ds_temp = ds_temp.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean temperature\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks (same as precipitation script)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0, 7):\n",
    "    mask = fire_ds[\"fire_label_Portugal\"] == label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\", \"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation functions\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Temperature\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Temperature\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build full DataFrame\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Save results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_temperature_correlations_by_fire_label_Portugal.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + temperature)\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3636e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Italy.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Italy.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Italy.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Italy.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Italy.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Temperature dataset (multiple yearly files)\n",
    "# --------------------\n",
    "temp_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_yearly_regridded\\daily_temperature_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in temp_files]\n",
    "ds_temp = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_temp = ds_temp.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_temp = ds_temp.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_temp = ds_temp.assign_coords(time=(\"date\", time_index))\n",
    "ds_temp = ds_temp.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean temperature\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Italy\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Temperature\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Temperature\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build combined DataFrame (pollutants + temperature)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_temperature_correlations_by_fire_label_Italy.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abdfb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + temperature)\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeceb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Spain.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Spain.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Spain.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Spain.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Spain.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Temperature dataset (multiple yearly files)\n",
    "# --------------------\n",
    "temp_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_yearly_regridded\\daily_temperature_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in temp_files]\n",
    "ds_temp = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_temp = ds_temp.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_temp = ds_temp.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_temp = ds_temp.assign_coords(time=(\"date\", time_index))\n",
    "ds_temp = ds_temp.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean temperature\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Spain\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Temperature\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Temperature\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build combined DataFrame (pollutants + temperature)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_temperature_correlations_by_fire_label_Spain.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9327d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + temperature)\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6794a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "\n",
    "# --------------------\n",
    "# 1. Pollutant files\n",
    "# --------------------\n",
    "pollutant_files = {\n",
    "    \"CO\": r\"D:\\IPMA\\CAMS\\co_fire_Greece.nc\",\n",
    "    \"PM2.5\": r\"D:\\IPMA\\CAMS\\pm2p5_fire_Greece.nc\",\n",
    "    \"PM10\": r\"D:\\IPMA\\CAMS\\pm10_fire_Greece.nc\",\n",
    "    \"NO2\": r\"D:\\IPMA\\CAMS\\no2_fire_Greece.nc\",\n",
    "    \"NO\": r\"D:\\IPMA\\CAMS\\no_fire_Greece.nc\"\n",
    "}\n",
    "\n",
    "pollutant_series = {}\n",
    "fire_ds = None\n",
    "\n",
    "for name, file in pollutant_files.items():\n",
    "    ds = xr.open_dataset(file)\n",
    "    ts = ds[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "    pollutant_series[name] = ts\n",
    "    if fire_ds is None:\n",
    "        fire_ds = ds  # keep dataset for fire labels\n",
    "\n",
    "# --------------------\n",
    "# 2. Temperature dataset (multiple yearly files)\n",
    "# --------------------\n",
    "temp_files = sorted(glob.glob(\n",
    "    r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_yearly_regridded\\daily_temperature_stats_*_regrid.nc\"\n",
    "))\n",
    "\n",
    "# Open all files and concatenate along 'Year'\n",
    "ds_list = [xr.open_dataset(f) for f in temp_files]\n",
    "ds_temp = xr.concat(ds_list, dim=\"Year\")\n",
    "\n",
    "# Stack Year, Month, Day into single dimension\n",
    "ds_temp = ds_temp.stack(date=(\"Year\", \"Month\", \"Day\"))\n",
    "\n",
    "# Build datetime index from the stacked coordinates\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only valid dates\n",
    "valid_mask = ~pd.isna(time_index)\n",
    "ds_temp = ds_temp.isel(date=valid_mask)\n",
    "time_index = time_index[valid_mask]\n",
    "\n",
    "# Assign time coordinate\n",
    "ds_temp = ds_temp.assign_coords(time=(\"date\", time_index))\n",
    "ds_temp = ds_temp.swap_dims({\"date\": \"time\"}).drop_vars(\"date\")\n",
    "\n",
    "# Daily spatial mean temperature\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "# --------------------\n",
    "# 3. Prepare FireLabel masks for each label (0-6)\n",
    "# --------------------\n",
    "fire_labels = {}\n",
    "for label in range(0,7):\n",
    "    mask = fire_ds[\"fire_label_Greece\"] == label\n",
    "    # True if any grid cell has this label\n",
    "    daily_label_present = mask.any(dim=[\"latitude\",\"longitude\"])\n",
    "    fire_labels[label] = daily_label_present.to_series()\n",
    "\n",
    "# --------------------\n",
    "# 4. Correlation function\n",
    "# --------------------\n",
    "def correlation_with_pvalues(df, pollutants):\n",
    "    results = []\n",
    "    for pol in pollutants:\n",
    "        x = df[pol]\n",
    "        y = df[\"Temperature\"]\n",
    "        if len(df) < 2 or x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": \"All\",\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def correlation_by_label(df, label_name, mask, pollutants):\n",
    "    results = []\n",
    "    subset = df[mask]\n",
    "    if len(subset) < 2:\n",
    "        return results\n",
    "    for pol in pollutants:\n",
    "        x = subset[pol]\n",
    "        y = subset[\"Temperature\"]\n",
    "        if x.nunique() < 2 or y.nunique() < 2:\n",
    "            continue\n",
    "        pearson_r, pearson_p = pearsonr(x, y)\n",
    "        spearman_r, spearman_p = spearmanr(x, y)\n",
    "        results.append({\n",
    "            \"FireLabel\": label_name,\n",
    "            \"Pollutant\": pol,\n",
    "            \"Pearson_r\": pearson_r,\n",
    "            \"Pearson_p\": pearson_p,\n",
    "            \"Spearman_r\": spearman_r,\n",
    "            \"Spearman_p\": spearman_p\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------\n",
    "# 5. Build combined DataFrame (pollutants + temperature)\n",
    "# --------------------\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "pollutant_names = list(pollutant_series.keys())\n",
    "all_results = []\n",
    "\n",
    "# Overall correlation\n",
    "all_results.extend(correlation_with_pvalues(df_all, pollutant_names))\n",
    "\n",
    "# Correlation by fire label\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    all_results.extend(correlation_by_label(df_all, label, mask_aligned, pollutant_names))\n",
    "\n",
    "# --------------------\n",
    "# 6. Print results\n",
    "# --------------------\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(r\"D:\\IPMA\\CAMS\\pollutant_temperature_correlations_by_fire_label_Greece.csv\", index=False)\n",
    "print(\"Correlation results saved to CSV.\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Print invalid dates removed\n",
    "# --------------------\n",
    "years = ds_temp[\"Year\"].values\n",
    "months = ds_temp[\"Month\"].values\n",
    "days = ds_temp[\"Day\"].values\n",
    "\n",
    "time_index = pd.to_datetime(\n",
    "    {\"year\": years, \"month\": months, \"day\": days}, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "invalid_dates = time_index[pd.isna(time_index)]\n",
    "if len(invalid_dates) > 0:\n",
    "    print(\"Invalid dates removed during datetime conversion:\")\n",
    "    for dt in invalid_dates:\n",
    "        print(dt)\n",
    "else:\n",
    "    print(\"No invalid dates found.\")\n",
    "\n",
    "# --------------------\n",
    "# Print number of days per fire label\n",
    "# --------------------\n",
    "# Build df_all (pollutants + temperature)\n",
    "temp_ts = ds_temp[\"Mean\"].mean(dim=[\"latitude\", \"longitude\"], skipna=True).to_series()\n",
    "temp_ts.name = \"Temperature\"\n",
    "\n",
    "df_all = pd.concat(list(pollutant_series.values()) + [temp_ts], axis=1,\n",
    "                   keys=list(pollutant_series.keys()) + [\"Temperature\"])\n",
    "\n",
    "print(\"\\nNumber of days per fire label:\")\n",
    "for label, mask in fire_labels.items():\n",
    "    # Align mask with df_all\n",
    "    mask_aligned = mask.reindex(df_all.index, fill_value=False)\n",
    "    \n",
    "    # Days before dropping NaNs\n",
    "    days_before = mask_aligned.sum()\n",
    "    \n",
    "    # Days after dropping NaNs\n",
    "    days_after = mask_aligned[mask_aligned & df_all.notna().all(axis=1)].sum()\n",
    "    \n",
    "    print(f\"Fire Label {label}: Before drop NaN = {days_before}, After drop NaN = {days_after}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
