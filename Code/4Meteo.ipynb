{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0159eacb",
   "metadata": {},
   "source": [
    "Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67240427",
   "metadata": {},
   "source": [
    "Convert lat and lon from 0.25 to 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73090de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_1999_2024_regrid.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Open dataset\n",
    "ds = xr.open_dataset(r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_1999_2024.nc\")\n",
    "\n",
    "factor_lat = 3\n",
    "factor_lon = 3\n",
    "\n",
    "# Step 1: Coarsen (aggregation)\n",
    "ds_coarse = xr.Dataset()\n",
    "for var in [\"Mean\", \"Median\", \"Std\", \"Max\", \"Min\"]:\n",
    "    ds_coarse[var] = ds[var].coarsen(latitude=factor_lat, longitude=factor_lon, boundary=\"trim\").mean()\n",
    "for var in [\"Total_Precipitation\", \"number\"]:\n",
    "    ds_coarse[var] = ds[var].coarsen(latitude=factor_lat, longitude=factor_lon, boundary=\"trim\").sum()\n",
    "\n",
    "# Copy non-spatial coords\n",
    "ds_coarse[\"Year\"] = ds[\"Year\"]\n",
    "ds_coarse[\"Month\"] = ds[\"Month\"]\n",
    "ds_coarse[\"Day\"] = ds[\"Day\"]\n",
    "\n",
    "# Step 2: Define target grid (forced)\n",
    "lat_target = np.arange(34.5, 66.0 + 0.001, 0.75)   # 43 lats\n",
    "lon_target = np.arange(-12.0, 36.0 + 0.001, 0.75)  # 65 lons\n",
    "\n",
    "# Step 3: Interpolate coarsened data onto target grid\n",
    "ds_final = ds_coarse.interp(latitude=lat_target, longitude=lon_target, method=\"linear\")\n",
    "\n",
    "# Save\n",
    "out_path = r\"D:\\IPMA\\ERA5\\Precipitation\\daily_precipitation_stats_1999_2024_regrid.nc\"\n",
    "ds_final.to_netcdf(out_path)\n",
    "print(\"✅ Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9246fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ad16279",
   "metadata": {},
   "source": [
    "Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6966e",
   "metadata": {},
   "source": [
    "Convert lat and lon from 0.25 to 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d1e05c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_regrid.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Open dataset\n",
    "ds = xr.open_dataset(r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats.nc\")\n",
    "\n",
    "factor_lat = 3\n",
    "factor_lon = 3\n",
    "\n",
    "# Step 1: Coarsen (aggregation)\n",
    "ds_coarse = xr.Dataset()\n",
    "for var in [\"Mean\", \"Median\", \"Std\", \"Max\", \"Min\"]:\n",
    "    ds_coarse[var] = ds[var].coarsen(latitude=factor_lat, longitude=factor_lon, boundary=\"trim\").mean()\n",
    "for var in [\"number\"]:\n",
    "    ds_coarse[var] = ds[var].coarsen(latitude=factor_lat, longitude=factor_lon, boundary=\"trim\").sum()\n",
    "\n",
    "# Copy non-spatial coords\n",
    "ds_coarse[\"Year\"] = ds[\"Year\"]\n",
    "ds_coarse[\"Month\"] = ds[\"Month\"]\n",
    "ds_coarse[\"Day\"] = ds[\"Day\"]\n",
    "\n",
    "# Step 2: Define target grid (forced)\n",
    "lat_target = np.arange(34.5, 66.0 + 0.001, 0.75)   # 43 lats\n",
    "lon_target = np.arange(-12.0, 36.0 + 0.001, 0.75)  # 65 lons\n",
    "\n",
    "# Step 3: Interpolate coarsened data onto target grid\n",
    "ds_final = ds_coarse.interp(latitude=lat_target, longitude=lon_target, method=\"linear\")\n",
    "\n",
    "# Save\n",
    "out_path = r\"D:\\IPMA\\ERA5\\Temperature\\daily_temperature_stats_regrid.nc\"\n",
    "ds_final.to_netcdf(out_path)\n",
    "print(\"✅ Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659cc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "563134be",
   "metadata": {},
   "source": [
    "Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate wind speed and direction based on u&v component\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Define folders\n",
    "input_folder = r\"E:\\IPMA\\ERA5\\UV_wind\\1raw_year_1979_2024\"\n",
    "output_folder = r\"E:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Find all relevant NetCDF files\n",
    "nc_files = sorted(glob(os.path.join(input_folder, \"ERA5_hourly_uv_*.nc\")))\n",
    "\n",
    "for file_path in nc_files:\n",
    "    print(f\"Processing {os.path.basename(file_path)}\")\n",
    "\n",
    "    # Open dataset\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    # Calculate wind speed\n",
    "    wind_speed = np.sqrt(ds['u10']**2 + ds['v10']**2)\n",
    "\n",
    "    # Calculate wind direction (degrees, meteorological convention)\n",
    "    wind_dir = (180 + np.degrees(np.arctan2(ds['u10'], ds['v10']))) % 360\n",
    "\n",
    "    # Add to dataset\n",
    "    ds = ds.assign(wind_speed=wind_speed, wind_direction=wind_dir)\n",
    "\n",
    "    # Add metadata\n",
    "    ds['wind_speed'].attrs['units'] = 'm/s'\n",
    "    ds['wind_speed'].attrs['description'] = '10m wind speed calculated from u10 and v10'\n",
    "    ds['wind_direction'].attrs['units'] = 'degrees'\n",
    "    ds['wind_direction'].attrs['description'] = 'Wind direction (from which wind blows, 0°=North, clockwise)'\n",
    "\n",
    "    # Create output filename, e.g., ERA5_hourly_wind_1979.nc\n",
    "    year_str = os.path.basename(file_path).split('_')[-1].split('.')[0]\n",
    "    out_filename = f\"ERA5_hourly_wind_{year_str}.nc\"\n",
    "    out_path = os.path.join(output_folder, out_filename)\n",
    "\n",
    "    # Save only the wind_speed and wind_direction variables (optional)\n",
    "    ds[['wind_speed', 'wind_direction']].to_netcdf(out_path)\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "print(\"✅ All files processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f116e",
   "metadata": {},
   "source": [
    "Daily statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b66b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2000.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2001.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2002.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2003.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2004.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2005.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2006.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2007.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2008.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2009.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2010.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2011.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2012.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2013.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2014.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2015.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2016.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2017.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2018.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2019.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2020.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2021.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2022.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2023.nc\n",
      "Processing: D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\\ERA5_hourly_wind_2024.nc\n",
      "✅ Daily wind speed dataset saved to: D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Folder with your wind files\n",
    "folder_path = r\"D:\\IPMA\\ERA5\\UV_wind\\2wind_speed_direction\"\n",
    "\n",
    "# Get sorted list of all NetCDF files in the folder\n",
    "file_list = sorted([f for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
    "\n",
    "# Initialize empty list to collect daily DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop over each file (one year per file)\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    print(f\"Processing: {file_path}\")\n",
    "    \n",
    "    # Open file lazily (to avoid memory overload)\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    ds = ds.chunk({'valid_time': 500})  # chunk time dimension\n",
    "    \n",
    "    # Add year, month, day as coordinates\n",
    "    ds = ds.assign_coords(\n",
    "        year=ds['valid_time'].dt.year,\n",
    "        month=ds['valid_time'].dt.month,\n",
    "        day=ds['valid_time'].dt.day\n",
    "    )\n",
    "    \n",
    "    # Loop through each unique day in the file\n",
    "    for day_val in np.unique(ds['day'].values):\n",
    "        ds_day = ds.sel(valid_time=ds['valid_time'].dt.day == day_val)\n",
    "        if ds_day['valid_time'].size == 0:\n",
    "            continue\n",
    "        \n",
    "        wind_data = ds_day['wind_speed'].values  # (time_in_day, lat, lon)\n",
    "\n",
    "        # Daily statistics\n",
    "        mean = np.nanmean(wind_data, axis=0)\n",
    "        median = np.nanmedian(wind_data, axis=0)\n",
    "        std = np.nanstd(wind_data, axis=0)\n",
    "        max_ = np.nanmax(wind_data, axis=0)\n",
    "        min_ = np.nanmin(wind_data, axis=0)\n",
    "\n",
    "        # Create Dataset for this day's stats\n",
    "        stats = xr.Dataset({\n",
    "            'Mean': (['latitude', 'longitude'], mean),\n",
    "            'Median': (['latitude', 'longitude'], median),\n",
    "            'Std': (['latitude', 'longitude'], std),\n",
    "            'Max': (['latitude', 'longitude'], max_),\n",
    "            'Min': (['latitude', 'longitude'], min_),\n",
    "        }, coords={'latitude': ds['latitude'], 'longitude': ds['longitude']})\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        stats_df = stats.to_dataframe().reset_index()\n",
    "\n",
    "        # Add date info\n",
    "        year_val = int(ds_day['year'].values[0])\n",
    "        month_val = int(ds_day['month'].values[0])\n",
    "        stats_df['Year'] = year_val\n",
    "        stats_df['Month'] = month_val\n",
    "        stats_df['Day'] = int(day_val)\n",
    "\n",
    "        # Set multi-index\n",
    "        stats_df = stats_df.set_index(['Year', 'Month', 'Day', 'latitude', 'longitude'])\n",
    "\n",
    "        df_list.append(stats_df)\n",
    "\n",
    "# Concatenate all daily results\n",
    "df_final = pd.concat(df_list)\n",
    "\n",
    "# Convert the DataFrame back to an xarray Dataset\n",
    "df_final_xr = df_final.reset_index().set_index(['Year', 'Month', 'Day', 'latitude', 'longitude'])\n",
    "df_final_xr = df_final_xr.to_xarray()\n",
    "\n",
    "# Save to NetCDF\n",
    "output_file_path = r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats.nc\"\n",
    "df_final_xr.to_netcdf(output_file_path)\n",
    "\n",
    "print(f\"✅ Daily wind speed dataset saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c693b14",
   "metadata": {},
   "source": [
    "Convert lat and lon from 0.25 to 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43ce9520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_regrid.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Open dataset\n",
    "ds = xr.open_dataset(r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats.nc\")\n",
    "\n",
    "factor_lat = 3\n",
    "factor_lon = 3\n",
    "\n",
    "# Step 1: Coarsen (aggregation)\n",
    "ds_coarse = xr.Dataset()\n",
    "for var in [\"Mean\", \"Median\", \"Std\", \"Max\", \"Min\"]:\n",
    "    ds_coarse[var] = ds[var].coarsen(latitude=factor_lat, longitude=factor_lon, boundary=\"trim\").mean()\n",
    "for var in [\"number\"]:\n",
    "    ds_coarse[var] = ds[var].coarsen(latitude=factor_lat, longitude=factor_lon, boundary=\"trim\").sum()\n",
    "\n",
    "# Copy non-spatial coords\n",
    "ds_coarse[\"Year\"] = ds[\"Year\"]\n",
    "ds_coarse[\"Month\"] = ds[\"Month\"]\n",
    "ds_coarse[\"Day\"] = ds[\"Day\"]\n",
    "\n",
    "# Step 2: Define target grid (forced)\n",
    "lat_target = np.arange(34.5, 66.0 + 0.001, 0.75)   # 43 lats\n",
    "lon_target = np.arange(-12.0, 36.0 + 0.001, 0.75)  # 65 lons\n",
    "\n",
    "# Step 3: Interpolate coarsened data onto target grid\n",
    "ds_final = ds_coarse.interp(latitude=lat_target, longitude=lon_target, method=\"linear\")\n",
    "\n",
    "# Save\n",
    "out_path = r\"D:\\IPMA\\ERA5\\UV_wind\\daily_wind_speed_stats_regrid.nc\"\n",
    "ds_final.to_netcdf(out_path)\n",
    "print(\"✅ Saved:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
