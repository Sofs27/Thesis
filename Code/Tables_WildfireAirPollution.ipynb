{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c18cae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb5837e9",
   "metadata": {},
   "source": [
    "mean +- standard error of mean of pollutants on day without fire, with fire and up to 5 days after fire outbreak - PORTUGAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings for invalid SEM calculations (e.g., count=0 or 1)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Load dataset\n",
    "ds = xr.open_dataset(r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\")\n",
    "\n",
    "# Extract PM10 and fire labels\n",
    "pm10 = ds['Mean']  # shape: (lat, lon, time)\n",
    "labels = ds['fire_label_Portugal'].transpose('latitude', 'longitude', 'time')\n",
    "\n",
    "print(\"\\nPM‚ÇÅ‚ÇÄ Mean ¬± SEM by Fire Label (spatial average across Portugal):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Label':<10}{'Mean (¬µg/m¬≥)':<20}{'SEM (¬µg/m¬≥)':<20}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Loop over labels 0‚Äì6\n",
    "for label in range(7):\n",
    "    # Mask PM10 where fire label matches\n",
    "    mask = labels == label\n",
    "    masked_pm10 = pm10.where(mask)\n",
    "\n",
    "    # Compute time-based stats per grid point\n",
    "    mean = masked_pm10.mean(dim='time', skipna=True)\n",
    "    std = masked_pm10.std(dim='time', skipna=True)\n",
    "    count = masked_pm10.count(dim='time')\n",
    "    sem = std / np.sqrt(count)\n",
    "\n",
    "    # Spatial mean\n",
    "    mean_val = mean.mean(skipna=True).item()\n",
    "    sem_val = sem.mean(skipna=True).item()\n",
    "\n",
    "    # Print formatted result\n",
    "    print(f\"{label:<10}{mean_val:<20.2f}{sem_val:<20.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, levene\n",
    "import warnings\n",
    "from scipy import stats\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Load dataset\n",
    "ds = xr.open_dataset(r\"D:\\IPMA\\CAMS\\pm10_fire_Portugal.nc\")\n",
    "\n",
    "pm10 = ds['Mean']  # Shape: (time, latitude, longitude)\n",
    "labels = ds['fire_label_Portugal'].transpose('time', 'latitude', 'longitude')\n",
    "\n",
    "# Compute spatial mean PM10 per day\n",
    "pm10_daily_avg = pm10.mean(dim=['latitude', 'longitude'], skipna=True)\n",
    "\n",
    "# Compute daily mode of fire labels (across lat/lon)\n",
    "def compute_mode_2d(x):\n",
    "    vals, counts = np.unique(x[~np.isnan(x)], return_counts=True)\n",
    "    return vals[np.argmax(counts)] if len(counts) > 0 else np.nan\n",
    "\n",
    "labels_daily_mode = xr.apply_ufunc(\n",
    "    compute_mode_2d,\n",
    "    labels,\n",
    "    input_core_dims=[['latitude', 'longitude']],\n",
    "    output_core_dims=[[]],\n",
    "    vectorize=True,\n",
    "    dask='parallelized',\n",
    "    output_dtypes=[float]\n",
    ")\n",
    "\n",
    "# Collect PM10 values per label\n",
    "label_pm10_values = {}\n",
    "\n",
    "print(\"Collecting daily PM‚ÇÅ‚ÇÄ averages for each fire label...\\n\")\n",
    "for label in range(7):\n",
    "    daily_vals = pm10_daily_avg.where(labels_daily_mode == label, drop=True).values\n",
    "    daily_vals = daily_vals[~np.isnan(daily_vals)]\n",
    "\n",
    "    if len(daily_vals) > 3:\n",
    "        label_pm10_values[label] = daily_vals\n",
    "        print(f\"Label {label}: {len(daily_vals)} daily values collected.\")\n",
    "\n",
    "# -- Shapiro-Wilk Test (normality check) --\n",
    "print(\"\\nüìä Shapiro‚ÄìWilk Normality Test:\")\n",
    "for label, values in label_pm10_values.items():\n",
    "    sample = values if len(values) <= 5000 else np.random.choice(values, 5000, replace=False)\n",
    "    stat, p = shapiro(sample)\n",
    "    result = \"Normal\" if p > 0.05 else \"Not normal\"\n",
    "    print(f\"Label {label}: W={stat:.3f}, p={p:.4f} ‚Üí {result}\")\n",
    "\n",
    "# -- Levene‚Äôs Test (equal variances) --\n",
    "print(\"\\nüìä Levene's Test for Equal Variances (homoscedasticity):\")\n",
    "group_labels = list(label_pm10_values.keys())\n",
    "grouped_values = [label_pm10_values[k] for k in group_labels if len(label_pm10_values[k]) > 10]\n",
    "\n",
    "if len(grouped_values) >= 2:\n",
    "    stat, p = levene(*grouped_values)\n",
    "    result = \"Equal variances\" if p > 0.05 else \"Unequal variances\"\n",
    "    print(f\"Levene‚Äôs statistic={stat:.3f}, p={p:.4f} ‚Üí {result}\")\n",
    "else:\n",
    "    print(\"Not enough groups with sufficient data for Levene‚Äôs test.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
